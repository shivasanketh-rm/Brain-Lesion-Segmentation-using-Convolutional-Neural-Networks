{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uu_LsonfD3eY"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import logging\n",
    "import pickle\n",
    "import yaml\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Function, Variable\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUqtyCgmD3ec"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ajrw4zvAD3ef",
    "outputId": "782c74e4-90d1-475c-c5da-ebbd5d909d89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P40'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled = False\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "uakEcW1TD3ei",
    "outputId": "19aa2101-e650-49b5-cdc1-4915d0c273cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices  1\n",
      "Active CUDA Device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HJGcohv0D3ek"
   },
   "outputs": [],
   "source": [
    "BN_MOMENTUM = 0.1\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv3d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rtCt1fmD3em"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes, momentum=BN_MOMENTUM)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "el68mZwZD3eo"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv3d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv3 = nn.Conv3d(planes, planes * self.expansion, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * self.expansion,\n",
    "                                  momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A6iwhyXDD3es"
   },
   "outputs": [],
   "source": [
    "class HighResolutionModule(nn.Module):\n",
    "    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,\n",
    "                 num_channels, fuse_method, multi_scale_output=True):\n",
    "        super(HighResolutionModule, self).__init__()\n",
    "        self._check_branches(\n",
    "            num_branches, blocks, num_blocks, num_inchannels, num_channels)\n",
    "\n",
    "        self.num_inchannels = num_inchannels\n",
    "        self.fuse_method = fuse_method\n",
    "        self.num_branches = num_branches\n",
    "\n",
    "        self.multi_scale_output = multi_scale_output\n",
    "\n",
    "        self.branches = self._make_branches(\n",
    "            num_branches, blocks, num_blocks, num_channels)\n",
    "        self.fuse_layers = self._make_fuse_layers()\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "    def _check_branches(self, num_branches, blocks, num_blocks,\n",
    "                        num_inchannels, num_channels):\n",
    "        if num_branches != len(num_blocks):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_BLOCKS({})'.format(\n",
    "                num_branches, len(num_blocks))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_channels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_CHANNELS({})'.format(\n",
    "                num_branches, len(num_channels))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_inchannels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_INCHANNELS({})'.format(\n",
    "                num_branches, len(num_inchannels))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "    def _make_one_branch(self, branch_index, block, num_blocks, num_channels,\n",
    "                         stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or \\\n",
    "           self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(\n",
    "                    self.num_inchannels[branch_index],\n",
    "                    num_channels[branch_index] * block.expansion,\n",
    "                    kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm3d(\n",
    "                    num_channels[branch_index] * block.expansion,\n",
    "                    momentum=BN_MOMENTUM\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.num_inchannels[branch_index],\n",
    "                num_channels[branch_index],\n",
    "                stride,\n",
    "                downsample\n",
    "            )\n",
    "        )\n",
    "        self.num_inchannels[branch_index] = \\\n",
    "            num_channels[branch_index] * block.expansion\n",
    "        for i in range(1, num_blocks[branch_index]):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.num_inchannels[branch_index],\n",
    "                    num_channels[branch_index]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n",
    "        branches = []\n",
    "\n",
    "        for i in range(num_branches):\n",
    "            branches.append(\n",
    "                self._make_one_branch(i, block, num_blocks, num_channels)\n",
    "            )\n",
    "\n",
    "        return nn.ModuleList(branches)\n",
    "\n",
    "    def _make_fuse_layers(self):\n",
    "        if self.num_branches == 1:\n",
    "            return None\n",
    "\n",
    "        num_branches = self.num_branches\n",
    "        num_inchannels = self.num_inchannels\n",
    "        fuse_layers = []\n",
    "        for i in range(num_branches if self.multi_scale_output else 1):\n",
    "            fuse_layer = []\n",
    "            for j in range(num_branches):\n",
    "                if j > i:\n",
    "                    fuse_layer.append(\n",
    "                        nn.Sequential(\n",
    "                            nn.Conv3d(\n",
    "                                num_inchannels[j],\n",
    "                                num_inchannels[i],\n",
    "                                1, 1, 0, bias=False\n",
    "                            ),\n",
    "                            nn.BatchNorm3d(num_inchannels[i]),\n",
    "                            nn.Upsample(scale_factor=2**(j-i), mode='nearest')\n",
    "                        )\n",
    "                    )\n",
    "                elif j == i:\n",
    "                    fuse_layer.append(None)\n",
    "                else:\n",
    "                    conv3x3s = []\n",
    "                    for k in range(i-j):\n",
    "                        if k == i - j - 1:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[i]\n",
    "                            conv3x3s.append(\n",
    "                                nn.Sequential(\n",
    "                                    nn.Conv3d(\n",
    "                                        num_inchannels[j],\n",
    "                                        num_outchannels_conv3x3,\n",
    "                                        3, 2, 1, bias=False\n",
    "                                    ),\n",
    "                                    nn.BatchNorm3d(num_outchannels_conv3x3)\n",
    "                                )\n",
    "                            )\n",
    "                        else:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[j]\n",
    "                            conv3x3s.append(\n",
    "                                nn.Sequential(\n",
    "                                    nn.Conv3d(\n",
    "                                        num_inchannels[j],\n",
    "                                        num_outchannels_conv3x3,\n",
    "                                        3, 2, 1, bias=False\n",
    "                                    ),\n",
    "                                    nn.BatchNorm3d(num_outchannels_conv3x3),\n",
    "                                    nn.ReLU(True)\n",
    "                                )\n",
    "                            )\n",
    "                    fuse_layer.append(nn.Sequential(*conv3x3s))\n",
    "            fuse_layers.append(nn.ModuleList(fuse_layer))\n",
    "\n",
    "        return nn.ModuleList(fuse_layers)\n",
    "\n",
    "    def get_num_inchannels(self):\n",
    "        return self.num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.num_branches == 1:\n",
    "            return [self.branches[0](x[0])]\n",
    "\n",
    "        for i in range(self.num_branches):\n",
    "            x[i] = self.branches[i](x[i])\n",
    "\n",
    "        x_fuse = []\n",
    "\n",
    "        for i in range(len(self.fuse_layers)):\n",
    "            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n",
    "            for j in range(1, self.num_branches):\n",
    "                if i == j:\n",
    "                    y = y + x[j]\n",
    "                else:\n",
    "                    y = y + self.fuse_layers[i][j](x[j])\n",
    "            x_fuse.append(self.relu(y))\n",
    "\n",
    "        return x_fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-42B801OD3eu"
   },
   "outputs": [],
   "source": [
    "blocks_dict = {\n",
    "    'BASIC': BasicBlock,\n",
    "    'BOTTLENECK': Bottleneck\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIk-FJiHD3ew"
   },
   "outputs": [],
   "source": [
    "class PoseHighResolutionNet(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        self.inplanes = 64\n",
    "        extra = cfg['MODEL']['EXTRA']\n",
    "        super(PoseHighResolutionNet, self).__init__()\n",
    "\n",
    "        # stem net\n",
    "        self.conv1 = nn.Conv3d(1, 64, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv3d(64, 64, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(64, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(Bottleneck, 64, 4)\n",
    "\n",
    "        self.stage2_cfg = extra['STAGE2']\n",
    "        num_channels = self.stage2_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage2_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))\n",
    "        ]\n",
    "        self.transition1 = self._make_transition_layer([256], num_channels)\n",
    "        self.stage2, pre_stage_channels = self._make_stage(\n",
    "            self.stage2_cfg, num_channels)\n",
    "\n",
    "        self.stage3_cfg = extra['STAGE3']\n",
    "        num_channels = self.stage3_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage3_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))\n",
    "        ]\n",
    "        self.transition2 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage3, pre_stage_channels = self._make_stage(\n",
    "            self.stage3_cfg, num_channels)\n",
    "\n",
    "        self.stage4_cfg = extra['STAGE4']\n",
    "        num_channels = self.stage4_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage4_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))\n",
    "        ]\n",
    "        self.transition3 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage4, pre_stage_channels = self._make_stage(\n",
    "            self.stage4_cfg, num_channels, multi_scale_output=False)\n",
    "\n",
    "        self.final_layer_1 = nn.Conv3d(\n",
    "            in_channels=pre_stage_channels[0],\n",
    "            out_channels=cfg['MODEL']['NUM_JOINTS'],\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.final_layer_2 = nn.Conv3d(\n",
    "            in_channels=2,\n",
    "            out_channels=1,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "        self.sigmoid = F.sigmoid\n",
    "\n",
    "\n",
    "    def _make_transition_layer(\n",
    "            self, num_channels_pre_layer, num_channels_cur_layer):\n",
    "        num_branches_cur = len(num_channels_cur_layer)\n",
    "        num_branches_pre = len(num_channels_pre_layer)\n",
    "\n",
    "        transition_layers = []\n",
    "        for i in range(num_branches_cur):\n",
    "            if i < num_branches_pre:\n",
    "                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n",
    "                    transition_layers.append(\n",
    "                        nn.Sequential(\n",
    "                            nn.Conv3d(\n",
    "                                num_channels_pre_layer[i],\n",
    "                                num_channels_cur_layer[i],\n",
    "                                3, 1, 1, bias=False\n",
    "                            ),\n",
    "                            nn.BatchNorm3d(num_channels_cur_layer[i]),\n",
    "                            nn.ReLU(inplace=True)\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    transition_layers.append(None)\n",
    "            else:\n",
    "                conv3x3s = []\n",
    "                for j in range(i+1-num_branches_pre):\n",
    "                    inchannels = num_channels_pre_layer[-1]\n",
    "                    outchannels = num_channels_cur_layer[i] \\\n",
    "                        if j == i-num_branches_pre else inchannels\n",
    "                    conv3x3s.append(\n",
    "                        nn.Sequential(\n",
    "                            nn.Conv3d(\n",
    "                                inchannels, outchannels, 3, 2, 1, bias=False\n",
    "                            ),\n",
    "                            nn.BatchNorm3d(outchannels),\n",
    "                            nn.ReLU(inplace=True)\n",
    "                        )\n",
    "                    )\n",
    "                transition_layers.append(nn.Sequential(*conv3x3s))\n",
    "\n",
    "        return nn.ModuleList(transition_layers)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(\n",
    "                    self.inplanes, planes * block.expansion,\n",
    "                    kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm3d(planes * block.expansion, momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_stage(self, layer_config, num_inchannels,\n",
    "                    multi_scale_output=True):\n",
    "        num_modules = layer_config['NUM_MODULES']\n",
    "        num_branches = layer_config['NUM_BRANCHES']\n",
    "        num_blocks = layer_config['NUM_BLOCKS']\n",
    "        num_channels = layer_config['NUM_CHANNELS']\n",
    "        block = blocks_dict[layer_config['BLOCK']]\n",
    "        fuse_method = layer_config['FUSE_METHOD']\n",
    "\n",
    "        modules = []\n",
    "        for i in range(num_modules):\n",
    "            # multi_scale_output is only used last module\n",
    "            if not multi_scale_output and i == num_modules - 1:\n",
    "                reset_multi_scale_output = False\n",
    "            else:\n",
    "                reset_multi_scale_output = True\n",
    "\n",
    "            modules.append(\n",
    "                HighResolutionModule(\n",
    "                    num_branches,\n",
    "                    block,\n",
    "                    num_blocks,\n",
    "                    num_inchannels,\n",
    "                    num_channels,\n",
    "                    fuse_method,\n",
    "                    reset_multi_scale_output\n",
    "                )\n",
    "            )\n",
    "            num_inchannels = modules[-1].get_num_inchannels()\n",
    "\n",
    "        return nn.Sequential(*modules), num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage2_cfg['NUM_BRANCHES']):\n",
    "            if self.transition1[i] is not None:\n",
    "                x_list.append(self.transition1[i](x))\n",
    "            else:\n",
    "                x_list.append(x)\n",
    "        y_list = self.stage2(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage3_cfg['NUM_BRANCHES']):\n",
    "            if self.transition2[i] is not None:\n",
    "                x_list.append(self.transition2[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        y_list = self.stage3(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage4_cfg['NUM_BRANCHES']):\n",
    "            if self.transition3[i] is not None:\n",
    "                x_list.append(self.transition3[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        y_list = self.stage4(x_list)\n",
    "\n",
    "        x = self.final_layer_1(y_list[0])\n",
    "        x = self.final_layer_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        #print(x.size())\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nqg1lMhAD3ey"
   },
   "outputs": [],
   "source": [
    "cfg = {'MODEL' : \n",
    "                {'SIGMA': 2, 'EXTRA': \n",
    "                                    {'FINAL_CONV_KERNEL': 1, \n",
    "                                    \n",
    "                                    'STAGE2': {'NUM_CHANNELS': [32, 64], 'NUM_MODULES': 1, 'FUSE_METHOD': 'SUM', 'BLOCK': 'BASIC', 'NUM_BRANCHES': 2, 'NUM_BLOCKS': [4, 4]}, \n",
    "                                    \n",
    "                                    'STAGE4': {'NUM_CHANNELS': [32, 64, 128, 256], 'NUM_MODULES': 3, 'FUSE_METHOD': 'SUM', 'BLOCK': 'BASIC', 'NUM_BRANCHES': 4, 'NUM_BLOCKS': [4, 4, 4, 4]}, \n",
    "                                    \n",
    "                                    'STAGE3': {'NUM_CHANNELS': [32, 64, 128], 'NUM_MODULES': 4, 'FUSE_METHOD': 'SUM', 'BLOCK': 'BASIC', 'NUM_BRANCHES': 3, 'NUM_BLOCKS': [4, 4, 4]}}, \n",
    "                                    \n",
    "                                    'NAME': 'hrnet', \n",
    "                                    'INIT_WEIGHTS': True, \n",
    "                                    'NUM_JOINTS': 2}}\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "V59ZYrQmD3e0",
    "outputId": "74931a1b-46ba-42e1-b445-41e019f147ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network:  84791749\n"
     ]
    }
   ],
   "source": [
    "net = PoseHighResolutionNet(cfg)\n",
    "net = nn.DataParallel(net)\n",
    "n_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print('Number of parameters in network: ', n_params)\n",
    "#2d : 28536113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ueUxUHzSEdrk",
    "outputId": "c2adccf1-9af8-4ce7-ba81-78f7e80676ce"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_imBvAxzD3e2"
   },
   "outputs": [],
   "source": [
    "# Path to the folder that contains folders of segmentation data\n",
    "#train_path = \"C:\\\\SSRM\\\\Unprocessed training dataset\\\\TrainingDataset_MSSEG\\\\train\\\\*\\\\\"\n",
    "#test_path = \"C:\\\\SSRM\\\\Unprocessed training dataset\\\\TrainingDataset_MSSEG\\\\test\\\\*\\\\\"\n",
    "#val_path = \"C:\\\\SSRM\\\\Unprocessed training dataset\\\\TrainingDataset_MSSEG\\\\val\\\\*\\\\\"\n",
    "\n",
    "train_path = \"data/Preprocessed/train/*/\"\n",
    "test_path = \"data/Preprocessed/test/*/\"\n",
    "val_path = \"data/Preprocessed/validation/*/\"\n",
    "\n",
    "train_image_mask_paths = []\n",
    "test_image_mask_paths = []\n",
    "val_image_mask_paths = []\n",
    "\n",
    "\n",
    "block_size = (16,16,16)\n",
    "\n",
    "#Load training images\n",
    "directory_paths = glob(train_path)\n",
    "for path in directory_paths:\n",
    "    # Load all the paths for each Flair set of data (1 Flair data and all its segmentation paths)\n",
    "    flair_path = path + 'FLAIR_preprocessed.nii.gz'\n",
    "    seg_path = path + 'Consensus.nii.gz'\n",
    "    train_image_mask_paths.append((flair_path,seg_path))\n",
    "    \n",
    "directory_paths = glob(test_path)\n",
    "for path in directory_paths:\n",
    "    # Load all the paths for each Flair set of data (1 Flair data and all its segmentation paths)\n",
    "    flair_path = path + 'FLAIR_preprocessed.nii.gz'\n",
    "    seg_path = path + 'Consensus.nii.gz'\n",
    "    test_image_mask_paths.append((flair_path,seg_path))\n",
    "    \n",
    "directory_paths = glob(val_path)\n",
    "for path in directory_paths:\n",
    "    # Load all the paths for each Flair set of data (1 Flair data and all its segmentation paths)\n",
    "    flair_path = path + 'FLAIR_preprocessed.nii.gz'\n",
    "    seg_path = path + 'Consensus.nii.gz'\n",
    "    val_image_mask_paths.append((flair_path,seg_path))\n",
    "\n",
    "#train_image_mask_paths = train_image_mask_paths[:1]\n",
    "#test_image_mask_paths = test_image_mask_paths[:1]\n",
    "val_image_mask_paths = val_image_mask_paths[:1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4otHgcMD3e6"
   },
   "outputs": [],
   "source": [
    "def zero_padding(data, block_size):\n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[0]/block_size[0])\n",
    "    #Calculate required padding size \n",
    "    pad_val_c = (block_size[0] * ceil_val) - data.shape[0]\n",
    "    \n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[1]/block_size[1])\n",
    "    #Calculate required padding size\n",
    "    pad_val_h = (block_size[1] * ceil_val) - data.shape[1]\n",
    "    \n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[2]/block_size[2])\n",
    "    # Calculate required padding size\n",
    "    pad_val_w = (block_size[2] * ceil_val) - data.shape[2]\n",
    "    \n",
    "    # Constant padding\n",
    "    #data = data.numpy()\n",
    "    data = np.pad(data, ((0,pad_val_c),(0,pad_val_h),(0,pad_val_w)), 'constant')\n",
    "    #data = np.array(data, dtype=np.int16)\n",
    "    \n",
    "    #changed dtype to float\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_data_blocks(data, block_size ):\n",
    "    x = torch.from_numpy(data)\n",
    "    # Add a dimension at 0th position\n",
    "    x = x.unsqueeze(0)\n",
    "    # Kernel Size\n",
    "    kc, kh, kw = block_size[0], block_size[1], block_size[2]\n",
    "    # stride\n",
    "    dc, dh, dw = block_size[0], block_size[1], block_size[2]\n",
    "    patches = x.unfold(1, kc, dc).unfold(2, kh, dh).unfold(3, kw, dw)\n",
    "    unfold_shape = patches.size()\n",
    "    patches = patches.contiguous().view(patches.size(0), -1, kc, kh, kw)\n",
    "    #Return Patches and Unfold Shape\n",
    "    return patches, unfold_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6nPIEz9D3e-"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_mask_paths):\n",
    "    img_mask_list = []\n",
    "\n",
    "    for i in tqdm(range(len(image_mask_paths))):\n",
    "        \n",
    "        #load the img and mask\n",
    "        vol = nib.load(image_mask_paths[i][0])\n",
    "        m = nib.load(image_mask_paths[i][1])\n",
    "        \n",
    "        # Get data, normalize the image and pad\n",
    "        img = np.array(vol.get_data(), np.float32) \n",
    "        img = img / np.amax(img)\n",
    "        img_padded = zero_padding(img, block_size)\n",
    "        \n",
    "        mask = np.array(m.get_data(),np.uint8)\n",
    "        mask = mask / np.amax(mask)\n",
    "        mask_padded = zero_padding(mask, block_size)\n",
    "\n",
    "        # Generate data blocks of block_size\n",
    "        img_blocks, unfold_shape_img = get_data_blocks(data = img_padded, block_size = block_size)\n",
    "        mask_blocks, unfold_shape_mask = get_data_blocks(data = mask_padded, block_size = block_size)\n",
    "\n",
    "        img_array = img_blocks.numpy()\n",
    "        #print(img_array.shape)\n",
    "        #img_array = img_array[:,3606:3607, : , : ]\n",
    "        #print(block_img.shape)\n",
    "        mask_array = mask_blocks.numpy()\n",
    "        #mask_array = mask_array[:,3606:3607, : , : ]\n",
    "        #print(block_mask.shape)\n",
    "        #print(np.sum(block_mask))\n",
    "        \n",
    "        '''final_sum = 0\n",
    "        #print(mask_array.shape[1])\n",
    "        for i in range(mask_array.shape[1]):\n",
    "            temp_sum = np.sum(mask_array[:,i:i+1, : , : ])\n",
    "            if temp_sum > final_sum:\n",
    "                final_sum = temp_sum\n",
    "                block_mask = mask_array[:,i:i+1, : , : ]\n",
    "                block_img = img_array[:,i:i+1, : , : ]\n",
    "                #print(temp_sum)\n",
    "                index = i\n",
    "                #print(\"index = \", i)\n",
    "\n",
    "        img_array = block_img\n",
    "        mask_array = block_mask'''\n",
    "        \n",
    "        #mask_array = mask_array[: , :mask_array.shape[1]//4, : , :]\n",
    "        #img_array = img_array[: , :img_array.shape[1]//4, : , :]\n",
    "        #print(mask_array.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(len(img_array[0])):\n",
    "            if np.sum(mask_array[0][i]) !=0:\n",
    "                img_mask_list.append((img_array[0][i], mask_array[0][i]))\n",
    "\n",
    "    return img_mask_list \n",
    "#a = preprocess_image(train_image_mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "B41IKdLQD3fA",
    "outputId": "5945363a-0221-4372-ca7d-83b793d7a231"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:13<00:00,  1.53s/it]\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.49s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of blocks containing lesion:  1678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#print(train_image_mask_paths)\n",
    "#Training:\n",
    "train_img_masks = preprocess_image(train_image_mask_paths)\n",
    "\n",
    "#Training:\n",
    "test_img_masks = preprocess_image(test_image_mask_paths)\n",
    "\n",
    "#Validation:\n",
    "val_img_masks = preprocess_image(val_image_mask_paths)\n",
    "\n",
    "print('No. of blocks containing lesion: ',len(train_img_masks))\n",
    "#print(len(val_img_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "snD8Ydu6H3lM"
   },
   "outputs": [],
   "source": [
    "train_val_masks = []\n",
    "train_val_masks.extend(train_img_masks)\n",
    "train_val_masks.extend(val_img_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_un0iZWnD3fE"
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Convert ndarrays in sample to Tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['img'], sample['label']\n",
    "        image = image[None,:,:]\n",
    "        label = label[None,:,:]\n",
    "\n",
    "        return {'img': torch.from_numpy(image.copy()).type(torch.FloatTensor),\n",
    "                'label': torch.from_numpy(label.copy()).type(torch.FloatTensor)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05ctT9BmD3fG"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_masks, transforms=None):\n",
    "\n",
    "        self.image_masks = image_masks\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):  # return count of sample we have\n",
    "\n",
    "        return len(self.image_masks)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = self.image_masks[index][0] # H, W, C\n",
    "        mask = self.image_masks[index][1]\n",
    "\n",
    "#       image = np.transpose(image, axes=[2, 0, 1]) # C, H, W\n",
    "\n",
    "        sample = {'img': image, 'label': mask}\n",
    "\n",
    "        if transforms:\n",
    "            sample = self.transforms(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "train_dataset = CustomDataset(train_val_masks, transforms=transforms.Compose([ToTensor()]))\n",
    "val_dataset = CustomDataset(val_img_masks, transforms=transforms.Compose([ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I23Ck-nbD3fI"
   },
   "outputs": [],
   "source": [
    "\n",
    "# define dice coefficient \n",
    "class DiceCoeff(Function):\n",
    "    \"\"\"Dice coeff for one pair of input image and target image\"\"\"\n",
    "    def forward(self, prediction, target):\n",
    "        self.save_for_backward(prediction, target)\n",
    "        eps = 0.0001 # in case union = 0\n",
    "        # Calculate intersection and union. \n",
    "        # You can convert the input image into a vector with input.contiguous().view(-1)\n",
    "        # Then use torch.dot(A, B) to calculate the intersection.\n",
    "        A = prediction.view(-1)\n",
    "        B = target.view(-1)\n",
    "        inter = torch.dot(A.float(),B.float())\n",
    "        union = torch.sum(A.float()) + torch.sum(B.float()) - inter + eps\n",
    "        # Calculate DICE \n",
    "        d = inter / union\n",
    "        return d\n",
    "\n",
    "# Calculate dice coefficients for batches\n",
    "def dice_coeff(prediction, target):\n",
    "    \"\"\"Dice coeff for batches\"\"\"\n",
    "    s = torch.FloatTensor(1).zero_()\n",
    "    \n",
    "    # For each pair of input and target, call DiceCoeff().forward(prediction, target) to calculate dice coefficient\n",
    "    # Then average\n",
    "    for i, (a,b) in enumerate(zip(prediction, target)):\n",
    "        s += DiceCoeff().forward(a,b)\n",
    "    s = s / (i + 1)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x8edM4rDD3fK"
   },
   "outputs": [],
   "source": [
    "def eval_net(net, dataset):\n",
    "    # set net mode to evaluation\n",
    "    net.eval()\n",
    "    tot = 0\n",
    "    print('Validation began')\n",
    "    print('val len: ', len(dataset))\n",
    "    #print(next(net.parameters()).is_cuda)\n",
    "    for i, b in enumerate(dataset):\n",
    "        img = b['img'].to(device)\n",
    "        B = img.shape[0]\n",
    "        true_mask = b['label'].to(device)\n",
    "\n",
    "        # Feed the image to the network to get predicted mask\n",
    "        mask_pred = net.forward(img.float())\n",
    "        #print('predicted')\n",
    "        \n",
    "        # For all pixels in predicted mask, set them to 1 if larger than 0.5. Otherwise set them to 0\n",
    "        #mask_pred = mask_pred > 0.5\n",
    "        \n",
    "        # calculate dice_coeff()\n",
    "        # note that you should add all the dice_coeff in validation/testing dataset together\n",
    "        # call dice_coeff() here\n",
    "        masks_probs_flat = mask_pred.view(mask_pred.numel())\n",
    "        true_masks_flat = true_mask.view(true_mask.numel())\n",
    "        \n",
    "        tot += dice_coeff(true_masks_flat,masks_probs_flat)\n",
    "        #print('tot: ',tot)\n",
    "        #tot += dice_coeff(true_mask,mask_pred)\n",
    "        # Return average dice_coeff()\n",
    "    print('Validation done!')\n",
    "    return tot / (i + 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ULcWS3R2D3fM",
    "outputId": "0e4abafa-c90d-4779-fd28-50a6eb61ddae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "smtg_fDpIPhH"
   },
   "outputs": [],
   "source": [
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "#writer = SummaryWriter('/content/gdrive/My Drive/IVP Project/Dataset/runs/hrnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(input, target):\n",
    "    smooth = 1.\n",
    "\n",
    "    iflat = input.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    \n",
    "    return 1 - ((2. * intersection + smooth) /\n",
    "              (iflat.sum() + tflat.sum() + smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "colab_type": "code",
    "id": "vfkdDX-eD3fP",
    "outputId": "633b4975-c694-47fd-9e07-b1c2877f7f2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/400.\n",
      "0.0000 --- loss: 0.827476\n",
      "0.0298 --- loss: 8.603207\n",
      "0.0596 --- loss: 0.177520\n",
      "0.0894 --- loss: 0.120447\n",
      "0.1192 --- loss: 0.453063\n",
      "0.1490 --- loss: 0.311244\n",
      "0.1788 --- loss: 0.253262\n",
      "0.2086 --- loss: 0.224499\n",
      "0.2384 --- loss: 0.127449\n",
      "0.2682 --- loss: 0.134853\n",
      "0.2980 --- loss: 0.219378\n",
      "0.3278 --- loss: 0.215672\n",
      "0.3576 --- loss: 0.206397\n",
      "0.3874 --- loss: 0.205711\n",
      "0.4172 --- loss: 0.446368\n",
      "0.4470 --- loss: 0.442088\n",
      "0.4768 --- loss: 0.311061\n",
      "0.5066 --- loss: 0.169029\n",
      "0.5364 --- loss: 0.552770\n",
      "0.5662 --- loss: 0.183194\n",
      "0.5959 --- loss: 0.165732\n",
      "0.6257 --- loss: 0.350513\n",
      "0.6555 --- loss: 0.573462\n",
      "0.6853 --- loss: 0.171759\n",
      "0.7151 --- loss: 0.093578\n",
      "0.7449 --- loss: 0.061222\n",
      "0.7747 --- loss: 0.431967\n",
      "0.8045 --- loss: 0.133333\n",
      "0.8343 --- loss: 1.583256\n",
      "0.8641 --- loss: 0.080998\n",
      "0.8939 --- loss: 0.326599\n",
      "0.9237 --- loss: 0.195657\n",
      "0.9535 --- loss: 0.198137\n",
      "0.9833 --- loss: 0.092074\n",
      "1.0131 --- loss: 0.078587\n",
      "1.0429 --- loss: 0.075507\n",
      "Epoch finished ! Loss: 0.4354578933403106\n",
      "Starting epoch 2/400.\n",
      "0.0000 --- loss: 0.317916\n",
      "0.0298 --- loss: 0.063367\n",
      "0.0596 --- loss: 0.132287\n",
      "0.0894 --- loss: 0.119406\n",
      "0.1192 --- loss: 0.053926\n",
      "0.1490 --- loss: 0.685853\n",
      "0.1788 --- loss: 0.088836\n",
      "0.2086 --- loss: 0.075153\n",
      "0.2384 --- loss: 0.598541\n",
      "0.2682 --- loss: 0.134215\n",
      "0.2980 --- loss: 0.109503\n",
      "0.3278 --- loss: 0.814929\n",
      "0.3576 --- loss: 0.125495\n",
      "0.3874 --- loss: 0.478294\n",
      "0.4172 --- loss: 0.119688\n",
      "0.4470 --- loss: 0.183529\n",
      "0.4768 --- loss: 0.109781\n",
      "0.5066 --- loss: 0.095983\n",
      "0.5364 --- loss: 0.088519\n",
      "0.5662 --- loss: 0.266949\n",
      "0.5959 --- loss: 0.116478\n",
      "0.6257 --- loss: 0.073251\n",
      "0.6555 --- loss: 0.250741\n",
      "0.6853 --- loss: 2.462244\n",
      "0.7151 --- loss: 0.142956\n",
      "0.7449 --- loss: 0.096025\n",
      "0.7747 --- loss: 0.173119\n",
      "0.8045 --- loss: 0.173138\n",
      "0.8343 --- loss: 0.107946\n",
      "0.8641 --- loss: 0.230407\n",
      "0.8939 --- loss: 0.645096\n",
      "0.9237 --- loss: 0.158581\n",
      "0.9535 --- loss: 0.139920\n",
      "0.9833 --- loss: 0.426814\n",
      "1.0131 --- loss: 0.124875\n",
      "1.0429 --- loss: 0.723539\n",
      "Epoch finished ! Loss: 0.2218040802781011\n",
      "Starting epoch 3/400.\n",
      "0.0000 --- loss: 0.079972\n",
      "0.0298 --- loss: 0.148110\n",
      "0.0596 --- loss: 0.122227\n",
      "0.0894 --- loss: 0.196541\n",
      "0.1192 --- loss: 0.121570\n",
      "0.1490 --- loss: 0.141844\n",
      "0.1788 --- loss: 0.059954\n",
      "0.2086 --- loss: 0.161373\n",
      "0.2384 --- loss: 0.212008\n",
      "0.2682 --- loss: 0.095435\n",
      "0.2980 --- loss: 0.099033\n",
      "0.3278 --- loss: 1.390990\n",
      "0.3576 --- loss: 0.130619\n",
      "0.3874 --- loss: 0.123445\n",
      "0.4172 --- loss: 0.299023\n",
      "0.4470 --- loss: 0.060696\n",
      "0.4768 --- loss: 0.148999\n",
      "0.5066 --- loss: 0.270096\n",
      "0.5364 --- loss: 0.091441\n",
      "0.5662 --- loss: 0.126338\n",
      "0.5959 --- loss: 0.207763\n",
      "0.6257 --- loss: 0.142108\n",
      "0.6555 --- loss: 0.093712\n",
      "0.6853 --- loss: 0.450153\n",
      "0.7151 --- loss: 0.089645\n",
      "0.7449 --- loss: 0.170515\n",
      "0.7747 --- loss: 0.107102\n",
      "0.8045 --- loss: 0.578971\n",
      "0.8343 --- loss: 0.189278\n",
      "0.8641 --- loss: 0.441256\n",
      "0.8939 --- loss: 0.110152\n",
      "0.9237 --- loss: 0.153793\n",
      "0.9535 --- loss: 0.226400\n",
      "0.9833 --- loss: 0.552449\n",
      "1.0131 --- loss: 0.206024\n",
      "1.0429 --- loss: 0.083713\n",
      "Epoch finished ! Loss: 0.21586497215108133\n",
      "Starting epoch 4/400.\n",
      "0.0000 --- loss: 0.105242\n",
      "0.0298 --- loss: 0.080477\n",
      "0.0596 --- loss: 0.109319\n",
      "0.0894 --- loss: 0.093229\n",
      "0.1192 --- loss: 0.069711\n",
      "0.1490 --- loss: 0.148980\n",
      "0.1788 --- loss: 0.103128\n",
      "0.2086 --- loss: 0.071520\n",
      "0.2384 --- loss: 0.088241\n",
      "0.2682 --- loss: 0.087542\n",
      "0.2980 --- loss: 0.086064\n",
      "0.3278 --- loss: 0.258973\n",
      "0.3576 --- loss: 0.146545\n",
      "0.3874 --- loss: 0.167407\n",
      "0.4172 --- loss: 0.177538\n",
      "0.4470 --- loss: 0.206668\n",
      "0.4768 --- loss: 0.146418\n",
      "0.5066 --- loss: 0.134681\n",
      "0.5364 --- loss: 0.073818\n",
      "0.5662 --- loss: 0.205708\n",
      "0.5959 --- loss: 0.056336\n",
      "0.6257 --- loss: 0.579894\n",
      "0.6555 --- loss: 0.087849\n",
      "0.6853 --- loss: 0.056924\n",
      "0.7151 --- loss: 0.216505\n",
      "0.7449 --- loss: 0.093875\n",
      "0.7747 --- loss: 0.165560\n",
      "0.8045 --- loss: 0.079125\n",
      "0.8343 --- loss: 0.123326\n",
      "0.8641 --- loss: 0.132246\n",
      "0.8939 --- loss: 0.095366\n",
      "0.9237 --- loss: 0.079823\n",
      "0.9535 --- loss: 0.130323\n",
      "0.9833 --- loss: 0.103916\n",
      "1.0131 --- loss: 0.074703\n",
      "1.0429 --- loss: 0.078877\n",
      "Epoch finished ! Loss: 0.21697327923869164\n",
      "Starting epoch 5/400.\n",
      "0.0000 --- loss: 0.084113\n",
      "0.0298 --- loss: 0.093299\n",
      "0.0596 --- loss: 0.146072\n",
      "0.0894 --- loss: 0.097238\n",
      "0.1192 --- loss: 0.102374\n",
      "0.1490 --- loss: 0.133225\n",
      "0.1788 --- loss: 0.083029\n",
      "0.2086 --- loss: 0.230292\n",
      "0.2384 --- loss: 0.174436\n",
      "0.2682 --- loss: 0.086554\n",
      "0.2980 --- loss: 0.073198\n",
      "0.3278 --- loss: 0.371278\n",
      "0.3576 --- loss: 0.116325\n",
      "0.3874 --- loss: 0.070839\n",
      "0.4172 --- loss: 0.264391\n",
      "0.4470 --- loss: 0.132246\n",
      "0.4768 --- loss: 0.066362\n",
      "0.5066 --- loss: 0.102941\n",
      "0.5364 --- loss: 0.109569\n",
      "0.5662 --- loss: 0.078361\n",
      "0.5959 --- loss: 0.118687\n",
      "0.6257 --- loss: 0.111042\n",
      "0.6555 --- loss: 0.137958\n",
      "0.6853 --- loss: 0.145723\n",
      "0.7151 --- loss: 0.215989\n",
      "0.7449 --- loss: 0.300095\n",
      "0.7747 --- loss: 0.079428\n",
      "0.8045 --- loss: 0.108404\n",
      "0.8343 --- loss: 0.098641\n",
      "0.8641 --- loss: 0.127990\n",
      "0.8939 --- loss: 0.112313\n",
      "0.9237 --- loss: 0.171301\n",
      "0.9535 --- loss: 0.126504\n",
      "0.9833 --- loss: 0.096103\n",
      "1.0131 --- loss: 0.122602\n",
      "1.0429 --- loss: 0.303337\n",
      "Epoch finished ! Loss: 0.21500933125300306\n",
      "Starting epoch 6/400.\n",
      "0.0000 --- loss: 0.453173\n",
      "0.0298 --- loss: 0.091553\n",
      "0.0596 --- loss: 0.128159\n",
      "0.0894 --- loss: 0.104941\n",
      "0.1192 --- loss: 0.128472\n",
      "0.1490 --- loss: 0.089906\n",
      "0.1788 --- loss: 0.074082\n",
      "0.2086 --- loss: 0.059283\n",
      "0.2384 --- loss: 0.072010\n",
      "0.2682 --- loss: 0.158499\n",
      "0.2980 --- loss: 0.237002\n",
      "0.3278 --- loss: 0.181506\n",
      "0.3576 --- loss: 0.128175\n",
      "0.3874 --- loss: 0.603971\n",
      "0.4172 --- loss: 0.131657\n",
      "0.4470 --- loss: 0.143383\n",
      "0.4768 --- loss: 0.126779\n",
      "0.5066 --- loss: 0.144592\n",
      "0.5364 --- loss: 0.140668\n",
      "0.5662 --- loss: 0.068192\n",
      "0.5959 --- loss: 0.100756\n",
      "0.6257 --- loss: 0.090721\n",
      "0.6555 --- loss: 0.187682\n",
      "0.6853 --- loss: 0.072289\n",
      "0.7151 --- loss: 0.144278\n",
      "0.7449 --- loss: 0.117953\n",
      "0.7747 --- loss: 0.144750\n",
      "0.8045 --- loss: 0.120103\n",
      "0.8343 --- loss: 0.316701\n",
      "0.8641 --- loss: 0.165548\n",
      "0.8939 --- loss: 0.075975\n",
      "0.9237 --- loss: 0.115454\n",
      "0.9535 --- loss: 0.077915\n",
      "0.9833 --- loss: 0.938282\n",
      "1.0131 --- loss: 0.115504\n",
      "1.0429 --- loss: 0.128977\n",
      "Epoch finished ! Loss: 0.21395925644837635\n",
      "Starting epoch 7/400.\n",
      "0.0000 --- loss: 0.119721\n",
      "0.0298 --- loss: 0.163141\n",
      "0.0596 --- loss: 0.087654\n",
      "0.0894 --- loss: 0.101749\n",
      "0.1192 --- loss: 0.121500\n",
      "0.1490 --- loss: 0.091829\n",
      "0.1788 --- loss: 0.196753\n",
      "0.2086 --- loss: 0.069729\n",
      "0.2384 --- loss: 0.120862\n",
      "0.2682 --- loss: 0.126550\n",
      "0.2980 --- loss: 0.068748\n",
      "0.3278 --- loss: 0.174864\n",
      "0.3576 --- loss: 0.141393\n",
      "0.3874 --- loss: 0.138098\n",
      "0.4172 --- loss: 0.338027\n",
      "0.4470 --- loss: 0.120875\n",
      "0.4768 --- loss: 0.114885\n",
      "0.5066 --- loss: 0.589077\n",
      "0.5364 --- loss: 0.133521\n",
      "0.5662 --- loss: 0.061919\n",
      "0.5959 --- loss: 0.109622\n",
      "0.6257 --- loss: 0.059076\n",
      "0.6555 --- loss: 0.155730\n",
      "0.6853 --- loss: 0.141608\n",
      "0.7151 --- loss: 0.132077\n",
      "0.7449 --- loss: 0.329834\n",
      "0.7747 --- loss: 0.138535\n",
      "0.8045 --- loss: 0.298961\n",
      "0.8343 --- loss: 0.074206\n",
      "0.8641 --- loss: 0.235658\n",
      "0.8939 --- loss: 0.112951\n",
      "0.9237 --- loss: 0.130653\n",
      "0.9535 --- loss: 0.305446\n",
      "0.9833 --- loss: 0.092480\n",
      "1.0131 --- loss: 0.223658\n",
      "1.0429 --- loss: 0.048711\n",
      "Epoch finished ! Loss: 0.21524798108028695\n",
      "Starting epoch 8/400.\n",
      "0.0000 --- loss: 0.070991\n",
      "0.0298 --- loss: 0.476222\n",
      "0.0596 --- loss: 0.197865\n",
      "0.0894 --- loss: 0.294600\n",
      "0.1192 --- loss: 0.117319\n",
      "0.1490 --- loss: 0.079612\n",
      "0.1788 --- loss: 0.494691\n",
      "0.2086 --- loss: 0.084187\n",
      "0.2384 --- loss: 0.141938\n",
      "0.2682 --- loss: 0.303345\n",
      "0.2980 --- loss: 0.103598\n",
      "0.3278 --- loss: 0.106577\n",
      "0.3576 --- loss: 0.135643\n",
      "0.3874 --- loss: 0.038641\n",
      "0.4172 --- loss: 0.103772\n",
      "0.4470 --- loss: 0.070519\n",
      "0.4768 --- loss: 0.107313\n",
      "0.5066 --- loss: 0.166951\n",
      "0.5364 --- loss: 0.396063\n",
      "0.5662 --- loss: 0.289489\n",
      "0.5959 --- loss: 0.507494\n",
      "0.6257 --- loss: 0.119512\n",
      "0.6555 --- loss: 0.145450\n",
      "0.6853 --- loss: 0.114200\n",
      "0.7151 --- loss: 0.104782\n",
      "0.7449 --- loss: 0.113307\n",
      "0.7747 --- loss: 0.108632\n",
      "0.8045 --- loss: 0.151254\n",
      "0.8343 --- loss: 0.143537\n",
      "0.8641 --- loss: 0.110632\n",
      "0.8939 --- loss: 0.108381\n",
      "0.9237 --- loss: 0.165606\n",
      "0.9535 --- loss: 0.129664\n",
      "0.9833 --- loss: 0.155966\n",
      "1.0131 --- loss: 0.190348\n",
      "1.0429 --- loss: 0.128063\n",
      "Epoch finished ! Loss: 0.21765329537991907\n",
      "Starting epoch 9/400.\n",
      "0.0000 --- loss: 0.115224\n",
      "0.0298 --- loss: 0.146133\n",
      "0.0596 --- loss: 0.539886\n",
      "0.0894 --- loss: 0.177841\n",
      "0.1192 --- loss: 0.599152\n",
      "0.1490 --- loss: 0.585837\n",
      "0.1788 --- loss: 0.119159\n",
      "0.2086 --- loss: 0.134071\n",
      "0.2384 --- loss: 0.170575\n",
      "0.2682 --- loss: 0.154330\n",
      "0.2980 --- loss: 0.099515\n",
      "0.3278 --- loss: 0.156789\n",
      "0.3576 --- loss: 0.088168\n",
      "0.3874 --- loss: 0.153485\n",
      "0.4172 --- loss: 0.085178\n",
      "0.4470 --- loss: 0.092089\n",
      "0.4768 --- loss: 0.145166\n",
      "0.5066 --- loss: 0.127380\n",
      "0.5364 --- loss: 0.084634\n",
      "0.5662 --- loss: 0.084179\n",
      "0.5959 --- loss: 0.191920\n",
      "0.6257 --- loss: 0.274022\n",
      "0.6555 --- loss: 0.760926\n",
      "0.6853 --- loss: 0.132062\n",
      "0.7151 --- loss: 0.167190\n",
      "0.7449 --- loss: 0.104290\n",
      "0.7747 --- loss: 0.132862\n",
      "0.8045 --- loss: 0.195587\n",
      "0.8343 --- loss: 0.109395\n",
      "0.8641 --- loss: 0.082106\n",
      "0.8939 --- loss: 0.387773\n",
      "0.9237 --- loss: 0.815550\n",
      "0.9535 --- loss: 0.149587\n",
      "0.9833 --- loss: 0.142858\n",
      "1.0131 --- loss: 0.466857\n",
      "1.0429 --- loss: 0.730607\n",
      "Epoch finished ! Loss: 0.21494259311069905\n",
      "Starting epoch 10/400.\n",
      "0.0000 --- loss: 0.160480\n",
      "0.0298 --- loss: 0.219571\n",
      "0.0596 --- loss: 0.196613\n",
      "0.0894 --- loss: 0.133939\n",
      "0.1192 --- loss: 0.408828\n",
      "0.1490 --- loss: 0.146566\n",
      "0.1788 --- loss: 0.890436\n",
      "0.2086 --- loss: 0.260004\n",
      "0.2384 --- loss: 0.141221\n",
      "0.2682 --- loss: 0.140023\n",
      "0.2980 --- loss: 1.107657\n",
      "0.3278 --- loss: 0.169489\n",
      "0.3576 --- loss: 0.119470\n",
      "0.3874 --- loss: 1.199665\n",
      "0.4172 --- loss: 0.126568\n",
      "0.4470 --- loss: 0.093318\n",
      "0.4768 --- loss: 0.135703\n",
      "0.5066 --- loss: 0.128985\n",
      "0.5364 --- loss: 0.099848\n",
      "0.5662 --- loss: 0.116033\n",
      "0.5959 --- loss: 0.094965\n",
      "0.6257 --- loss: 0.105313\n",
      "0.6555 --- loss: 0.161481\n",
      "0.6853 --- loss: 0.131234\n",
      "0.7151 --- loss: 0.063950\n",
      "0.7449 --- loss: 0.085892\n",
      "0.7747 --- loss: 0.387510\n",
      "0.8045 --- loss: 0.235734\n",
      "0.8343 --- loss: 0.120932\n",
      "0.8641 --- loss: 0.122965\n",
      "0.8939 --- loss: 0.161224\n",
      "0.9237 --- loss: 0.392082\n",
      "0.9535 --- loss: 0.127704\n",
      "0.9833 --- loss: 0.073345\n",
      "1.0131 --- loss: 0.128216\n",
      "1.0429 --- loss: 0.314360\n",
      "Epoch finished ! Loss: 0.21727475467911908\n",
      "Starting epoch 11/400.\n",
      "0.0000 --- loss: 0.487299\n",
      "0.0298 --- loss: 0.656079\n",
      "0.0596 --- loss: 0.109934\n",
      "0.0894 --- loss: 0.140774\n",
      "0.1192 --- loss: 0.107544\n",
      "0.1490 --- loss: 0.099149\n",
      "0.1788 --- loss: 0.126537\n",
      "0.2086 --- loss: 0.053663\n",
      "0.2384 --- loss: 0.157304\n",
      "0.2682 --- loss: 0.119286\n",
      "0.2980 --- loss: 0.472153\n",
      "0.3278 --- loss: 0.133757\n",
      "0.3576 --- loss: 0.112303\n",
      "0.3874 --- loss: 0.119808\n",
      "0.4172 --- loss: 0.161401\n",
      "0.4470 --- loss: 0.105912\n",
      "0.4768 --- loss: 0.135688\n",
      "0.5066 --- loss: 0.132660\n",
      "0.5364 --- loss: 0.076384\n",
      "0.5662 --- loss: 0.120732\n",
      "0.5959 --- loss: 0.099729\n",
      "0.6257 --- loss: 0.092181\n",
      "0.6555 --- loss: 0.120549\n",
      "0.6853 --- loss: 0.122687\n",
      "0.7151 --- loss: 0.124722\n",
      "0.7449 --- loss: 0.108044\n",
      "0.7747 --- loss: 0.091855\n",
      "0.8045 --- loss: 0.159986\n",
      "0.8343 --- loss: 1.266536\n",
      "0.8641 --- loss: 0.095600\n",
      "0.8939 --- loss: 0.742950\n",
      "0.9237 --- loss: 0.813793\n",
      "0.9535 --- loss: 0.110409\n",
      "0.9833 --- loss: 0.142317\n",
      "1.0131 --- loss: 0.187696\n",
      "1.0429 --- loss: 0.200975\n",
      "Epoch finished ! Loss: 0.21733218968124457\n",
      "Starting epoch 12/400.\n",
      "0.0000 --- loss: 0.063017\n",
      "0.0298 --- loss: 0.115375\n",
      "0.0596 --- loss: 0.075571\n",
      "0.0894 --- loss: 0.217961\n",
      "0.1192 --- loss: 0.789204\n",
      "0.1490 --- loss: 0.229748\n",
      "0.1788 --- loss: 0.237377\n",
      "0.2086 --- loss: 0.105935\n",
      "0.2384 --- loss: 0.077450\n",
      "0.2682 --- loss: 0.373404\n",
      "0.2980 --- loss: 0.067583\n",
      "0.3278 --- loss: 0.267671\n",
      "0.3576 --- loss: 0.236604\n",
      "0.3874 --- loss: 0.074933\n",
      "0.4172 --- loss: 0.102985\n",
      "0.4470 --- loss: 0.123646\n",
      "0.4768 --- loss: 0.145831\n",
      "0.5066 --- loss: 0.133647\n",
      "0.5364 --- loss: 0.202527\n",
      "0.5662 --- loss: 0.183530\n",
      "0.5959 --- loss: 0.119170\n",
      "0.6257 --- loss: 0.162020\n",
      "0.6555 --- loss: 0.094998\n",
      "0.6853 --- loss: 0.120704\n",
      "0.7151 --- loss: 0.097209\n",
      "0.7449 --- loss: 0.585474\n",
      "0.7747 --- loss: 0.129418\n",
      "0.8045 --- loss: 0.189490\n",
      "0.8343 --- loss: 0.362834\n",
      "0.8641 --- loss: 0.207624\n",
      "0.8939 --- loss: 0.150111\n",
      "0.9237 --- loss: 0.094390\n",
      "0.9535 --- loss: 0.155153\n",
      "0.9833 --- loss: 0.469225\n",
      "1.0131 --- loss: 0.208673\n",
      "1.0429 --- loss: 0.130608\n",
      "Epoch finished ! Loss: 0.21539349689659937\n",
      "Starting epoch 13/400.\n",
      "0.0000 --- loss: 0.080722\n",
      "0.0298 --- loss: 0.057779\n",
      "0.0596 --- loss: 0.217399\n",
      "0.0894 --- loss: 0.078699\n",
      "0.1192 --- loss: 1.025150\n",
      "0.1490 --- loss: 0.195226\n",
      "0.1788 --- loss: 0.113715\n",
      "0.2086 --- loss: 0.070150\n",
      "0.2384 --- loss: 0.138832\n",
      "0.2682 --- loss: 0.969350\n",
      "0.2980 --- loss: 0.113985\n",
      "0.3278 --- loss: 0.088311\n",
      "0.3576 --- loss: 0.094298\n",
      "0.3874 --- loss: 0.061188\n",
      "0.4172 --- loss: 0.072419\n",
      "0.4470 --- loss: 0.104398\n",
      "0.4768 --- loss: 0.080633\n",
      "0.5066 --- loss: 0.134012\n",
      "0.5364 --- loss: 0.096365\n",
      "0.5662 --- loss: 0.173554\n",
      "0.5959 --- loss: 0.175175\n",
      "0.6257 --- loss: 0.106046\n",
      "0.6555 --- loss: 0.111277\n",
      "0.6853 --- loss: 0.174818\n",
      "0.7151 --- loss: 0.159059\n",
      "0.7449 --- loss: 0.165164\n",
      "0.7747 --- loss: 0.181298\n",
      "0.8045 --- loss: 0.130189\n",
      "0.8343 --- loss: 0.108644\n",
      "0.8641 --- loss: 0.140835\n",
      "0.8939 --- loss: 0.098980\n",
      "0.9237 --- loss: 0.188793\n",
      "0.9535 --- loss: 0.227100\n",
      "0.9833 --- loss: 0.138328\n",
      "1.0131 --- loss: 0.068798\n",
      "1.0429 --- loss: 0.094480\n",
      "Epoch finished ! Loss: 0.2152843072674644\n",
      "Starting epoch 14/400.\n",
      "0.0000 --- loss: 0.129141\n",
      "0.0298 --- loss: 0.153321\n",
      "0.0596 --- loss: 0.196410\n",
      "0.0894 --- loss: 0.134462\n",
      "0.1192 --- loss: 0.208508\n",
      "0.1490 --- loss: 0.124572\n",
      "0.1788 --- loss: 0.098779\n",
      "0.2086 --- loss: 0.472414\n",
      "0.2384 --- loss: 0.098405\n",
      "0.2682 --- loss: 0.103435\n",
      "0.2980 --- loss: 0.295283\n",
      "0.3278 --- loss: 0.088633\n",
      "0.3576 --- loss: 0.206053\n",
      "0.3874 --- loss: 0.154160\n",
      "0.4172 --- loss: 0.387500\n",
      "0.4470 --- loss: 0.342657\n",
      "0.4768 --- loss: 0.104775\n",
      "0.5066 --- loss: 0.351086\n",
      "0.5364 --- loss: 0.777698\n",
      "0.5662 --- loss: 0.222304\n",
      "0.5959 --- loss: 0.115554\n",
      "0.6257 --- loss: 0.084126\n",
      "0.6555 --- loss: 0.131413\n",
      "0.6853 --- loss: 0.055820\n",
      "0.7151 --- loss: 0.161818\n",
      "0.7449 --- loss: 0.105165\n",
      "0.7747 --- loss: 0.131919\n",
      "0.8045 --- loss: 0.096238\n",
      "0.8343 --- loss: 0.136552\n",
      "0.8641 --- loss: 0.206281\n",
      "0.8939 --- loss: 0.075817\n",
      "0.9237 --- loss: 0.100913\n",
      "0.9535 --- loss: 0.144910\n",
      "0.9833 --- loss: 0.097552\n",
      "1.0131 --- loss: 0.103277\n",
      "1.0429 --- loss: 0.153847\n",
      "Epoch finished ! Loss: 0.21979115938426744\n",
      "Starting epoch 15/400.\n",
      "0.0000 --- loss: 0.115097\n",
      "0.0298 --- loss: 0.087445\n",
      "0.0596 --- loss: 0.678111\n",
      "0.0894 --- loss: 0.101263\n",
      "0.1192 --- loss: 0.143184\n",
      "0.1490 --- loss: 0.049523\n",
      "0.1788 --- loss: 0.170357\n",
      "0.2086 --- loss: 0.081649\n",
      "0.2384 --- loss: 0.173819\n",
      "0.2682 --- loss: 0.126391\n",
      "0.2980 --- loss: 0.157355\n",
      "0.3278 --- loss: 0.082336\n",
      "0.3576 --- loss: 0.104307\n",
      "0.3874 --- loss: 0.068731\n",
      "0.4172 --- loss: 0.285102\n",
      "0.4470 --- loss: 0.231259\n",
      "0.4768 --- loss: 0.112539\n",
      "0.5066 --- loss: 0.173572\n",
      "0.5364 --- loss: 0.103033\n",
      "0.5662 --- loss: 0.257857\n",
      "0.5959 --- loss: 0.113607\n",
      "0.6257 --- loss: 0.168636\n",
      "0.6555 --- loss: 0.110883\n",
      "0.6853 --- loss: 0.057352\n",
      "0.7151 --- loss: 0.152456\n",
      "0.7449 --- loss: 0.094583\n",
      "0.7747 --- loss: 0.180509\n",
      "0.8045 --- loss: 0.092010\n",
      "0.8343 --- loss: 0.169420\n",
      "0.8641 --- loss: 0.124160\n",
      "0.8939 --- loss: 0.132443\n",
      "0.9237 --- loss: 0.083667\n",
      "0.9535 --- loss: 0.084313\n",
      "0.9833 --- loss: 0.080458\n",
      "1.0131 --- loss: 0.211124\n",
      "1.0429 --- loss: 1.038257\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-9bb5b20454d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# optimizer.step updates the value of x using the gradient x.grad.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch finished ! Loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mloss_graph_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/py3.6.3/lib/python3.6/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/py3.6.3/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/py3.6.3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "epochs = 400 # e.g. 10, or more until dice converge\n",
    "batch_size = 1 # e.g. 16\n",
    "lr = 0.01        # e.g. 0.01, 0.00001\n",
    "N_train = len(train_img_masks)\n",
    "model_save_path = './' #'/content/gdrive/My Drive/IVP Project/Dataset/models/hrnet/'  # directory to same the model after each epoch.\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(),lr = lr,momentum=0.99, weight_decay=0.0005)\n",
    "optimizer = optim.Adam(net.parameters(), lr = lr, weight_decay=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 100, gamma=0.1)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "net.to(device)\n",
    "loss_graph_values = {}\n",
    "loss_graph_list = []\n",
    "\n",
    "# Start training\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}/{}.'.format(epoch + 1, epochs))\n",
    "    net.train()\n",
    "    # Reload images and masks for training and validation and perform random shuffling at the begining of each epoch\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    #print('train len: ', len(train_loader))\n",
    "    #print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "    for i, b in enumerate(train_loader):\n",
    "        # Get images and masks from each batch\n",
    "        imgs = b['img']\n",
    "        true_masks = b['label']\n",
    "        \n",
    "        imgs = imgs.to(device)\n",
    "        true_masks = true_masks.to(device)\n",
    "        #print('True mask shape: ',true_masks.shape)\n",
    "        \n",
    "        # Feed your images into the network\n",
    "        masks_pred = net.forward(imgs.float())\n",
    "        #print('mask:',masks_pred.shape)\n",
    "        #print('true:',true_masks.shape)\n",
    "        masks_probs = masks_pred[:,0,:,:,:]\n",
    "        masks_probs = masks_probs.unsqueeze(1)\n",
    "\n",
    "        masks_probs_flat = masks_probs.reshape(1,-1)\n",
    "        masks_probs_flat = masks_probs_flat.squeeze()\n",
    "\n",
    "        true_masks_flat = true_masks.reshape(1,-1)\n",
    "        true_masks_flat = true_masks_flat.squeeze()\n",
    "\n",
    "        # Calculate the loss by comparing the predicted masks vector and true masks vector\n",
    "        # And sum the losses together\n",
    "        loss = criterion(masks_probs_flat,true_masks_flat.float())\n",
    "        #loss = dice_loss(masks_probs_flat,true_masks_flat.float())\n",
    "        epoch_loss += loss.item()\n",
    "        if count % 50 == 0:\n",
    "            print('{0:.4f} --- loss: {1:.6f}'.format(i * batch_size / N_train, loss.item()))\n",
    "        count = count + 1\n",
    "        # optimizer.zero_grad() clears x.grad for every parameter x in the optimizer.\n",
    "        # It’s important to call this before loss.backward(), otherwise you’ll accumulate the gradients from multiple passes.\n",
    "        optimizer.zero_grad()\n",
    "        # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "        # These are accumulated into x.grad for every parameter x\n",
    "        loss.backward()\n",
    "        # optimizer.step updates the value of x using the gradient x.grad.\n",
    "        optimizer.step()\n",
    "    print('Epoch finished ! Loss: {}'.format(epoch_loss / i))\n",
    "    loss_graph_values[epoch] = epoch_loss / i\n",
    "    loss_graph_list.append(epoch_loss / i)\n",
    "    #writer.add_scalar('training loss', (epoch_loss / (i+1)), epoch)\n",
    "\n",
    "    # Perform validation with eval_net() on the validation data\n",
    "    #val_dice = eval_net(net,val_loader)\n",
    "    #print('Validation Dice Coeff: {}'.format(val_dice))\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save the model after each epoch\n",
    "    '''if os.path.isdir(model_save_path):\n",
    "        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    else:\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    print('Checkpoint {} saved !'.format(epoch + 1))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''if os.path.isdir(model_save_path):\n",
    "    torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "else:\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "print('Checkpoint {} saved !'.format(epoch + 1))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation began\n",
      "val len:  98\n",
      "Validation done!\n",
      "Validation Dice Coeff: tensor([0.0351], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#net.load_state_dict(torch.load('Brain_Seg_Epoch116.pth'))\n",
    "#val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "val_dice = eval_net(net,val_loader)\n",
    "print('Validation Dice Coeff: {}'.format(val_dice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(net,full_img,out_threshold=0.1):\n",
    "    # set the mode of your network to evaluation\n",
    "    net.eval()\n",
    "\n",
    "    X_img = torch.from_numpy(full_img).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        output_img = net(X_img.float())\n",
    "        out_probs = output_img.squeeze(0).squeeze(0)\n",
    "        out_mask_np = (out_probs>out_threshold).cpu().numpy().astype('uint8')\n",
    "\n",
    "    return out_mask_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(blocks, unfold_shape):\n",
    "\n",
    "    blocks_orig = blocks.view(unfold_shape)\n",
    "    output_c = unfold_shape[1] * unfold_shape[4]\n",
    "    output_h = unfold_shape[2] * unfold_shape[5]\n",
    "    output_w = unfold_shape[3] * unfold_shape[6]\n",
    "    blocks_orig = blocks_orig.permute(0, 1, 4, 2, 5, 3, 6).contiguous()\n",
    "    blocks_orig = blocks_orig.view(1, output_c, output_h, output_w)\n",
    "    # Remove the dimension at 0th position and convert to numpy\n",
    "    blocks_orig = blocks_orig.squeeze(0).detach().numpy()\n",
    "    return blocks_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_masks_1 = [(train_img_masks[0][0], train_img_masks[0][1])]\n",
    "print(len(train_img_masks_1))\n",
    "print(train_img_masks_1[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pred = predict_img(net=net,full_img=train_img_masks_1[0][0], out_threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Image and mask alignment\n",
    "def show_slices(slices):\n",
    "    \"\"\" Function to display row of image slices \"\"\"\n",
    "    fig, axes = plt.subplots(1, len(slices), figsize=(8,8))\n",
    "    for i, slc in enumerate(slices):\n",
    "        axes[i].imshow(slc.T, cmap=\"gray\", origin=\"lower\")\n",
    "\n",
    "for i in range(1):\n",
    "    for j in range(len(train_img_masks[i][0][0][0])):\n",
    "        show_slices([train_img_masks_1[i][0][:, :, j], train_img_masks[i][1][:, :, j], mask_pred[:,:,j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_slices([train_img_masks_1[0][0][:,:,8], train_img_masks_1[0][1][:,:,8]])\n",
    "show_slices([train_img_masks_1[0][0][:,:,8], mask_pred[:,:,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "lists = sorted(loss_graph_values.items()) # sorted by key, return a list of tuples\n",
    "lists = lists[:200]\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_graph_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "HR-Net_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
