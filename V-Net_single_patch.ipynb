{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Function, Variable\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla K80'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELU(elu, nchan):\n",
    "    if elu:\n",
    "        return nn.ELU(inplace=True)\n",
    "    else:\n",
    "        return nn.PReLU(nchan)\n",
    "    \n",
    "def n_conv(nchan, depth, elu):\n",
    "    layers = []\n",
    "    for _ in range(depth):\n",
    "        layers.append(single_conv(nchan, elu))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class single_conv(nn.Module):\n",
    "    def __init__(self, nchan, elu):\n",
    "        super(single_conv, self).__init__()\n",
    "        self.relu = ELU(elu, nchan)\n",
    "        self.conv = nn.Conv3d(nchan, nchan, kernel_size=5, padding=2)\n",
    "        self.bn = nn.BatchNorm3d(nchan)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn(self.conv(x)))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class input_layer(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, elu):\n",
    "        super(input_layer, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv3d(in_ch,out_ch,kernel_size=5,padding=2)\n",
    "        self.relu = ELU(elu, out_ch)\n",
    "        self.bn = nn.BatchNorm3d(out_ch)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 1. Convolve\n",
    "        out = self.conv(x)\n",
    "        # 2. Normalize\n",
    "        out = self.bn(out)\n",
    "        # 3. Add output and input\n",
    "        out = torch.add(out, x)\n",
    "        # 4. Activation\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class down_layer(nn.Module):\n",
    "    def __init__(self, in_ch, nConv, elu):\n",
    "        super(down_layer, self).__init__()\n",
    "        out_ch = 2*in_ch\n",
    "        self.down_conv = nn.Conv3d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "        self.bn = nn.BatchNorm3d(out_ch)\n",
    "        self.relu = ELU(elu, out_ch)\n",
    "        self.layers = n_conv(out_ch, nConv, elu)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        down = self.relu(self.bn(self.down_conv(x)))\n",
    "        out = self.layers(down)\n",
    "        out = self.relu(torch.add(out, down))\n",
    "        return down, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class up_layer(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, nConv, elu):\n",
    "        super(up_layer, self).__init__()\n",
    "        self.up_conv = nn.ConvTranspose3d(in_ch, out_ch//2 , kernel_size=2, stride=2)\n",
    "        self.bn = nn.BatchNorm3d(out_ch//2 )\n",
    "        self.relu1 = ELU(elu, out_ch//2 )\n",
    "        self.relu2 = ELU(elu, out_ch)\n",
    "        self.layers = n_conv(out_ch, nConv, elu)\n",
    "        #self.do2 = nn.Dropout3d()\n",
    "\n",
    "    def forward(self, x, skipx):\n",
    "        out = self.relu1(self.bn(self.up_conv(x)))\n",
    "        xcat = torch.cat((out, skipx), 1)\n",
    "        out = self.layers(xcat)\n",
    "        out = self.relu2(torch.add(out, xcat))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class output_layer(nn.Module):\n",
    "    def __init__(self, in_ch, elu, nll):\n",
    "        super(output_layer, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_ch, 2, kernel_size=5, padding=2)\n",
    "        self.bn = nn.BatchNorm3d(2)\n",
    "        self.conv2 = nn.Conv3d(2, 1, kernel_size=1)\n",
    "        self.relu1 = ELU(elu, 2)\n",
    "        if nll:\n",
    "            self.softmax = F.log_softmax\n",
    "        else:\n",
    "            self.softmax = F.sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu1(self.bn(self.conv1(x)))\n",
    "        out = self.conv2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, elu=True, nll=False):\n",
    "        super(VNet, self).__init__()\n",
    "        #In\n",
    "        self.input = input_layer(1, 16, elu)\n",
    "        \n",
    "        #Down\n",
    "        self.down32 = down_layer(16, 1, elu)\n",
    "        self.down64 = down_layer(32, 2, elu)\n",
    "        self.down128 = down_layer(64, 3, elu)\n",
    "        self.down256 = down_layer(128, 2, elu)\n",
    "        \n",
    "        #Up\n",
    "        self.up256 = up_layer(256,256, 2, elu)\n",
    "        self.up128 = up_layer(256,128, 2, elu)\n",
    "        self.up64 = up_layer(128,64, 1, elu)\n",
    "        self.up32 = up_layer(64,32, 1, elu)\n",
    "        \n",
    "        #Out\n",
    "        self.output = output_layer(32, elu, nll)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #Layer 1: In\n",
    "        out16 = self.input(x)\n",
    "        \n",
    "        #Layer 2 : Down ( 2 conv layers deep)\n",
    "        d_32, out32 = self.down32(out16)\n",
    "        \n",
    "        #Layer 3 : Down ( 3 conv layers deep)\n",
    "        d_64, out64 = self.down64(out32)\n",
    "        \n",
    "        #Layer 4 : Down ( 3 conv layers deep)\n",
    "        d_128, out128 = self.down128(out64)      \n",
    "        \n",
    "        #Layer 5 : Down ( 3 conv layers deep)\n",
    "        d_256, out256 = self.down256(out128)\n",
    "        \n",
    "        #Layer 5 : up ( 3 conv layers deep)\n",
    "        output = self.up256(out256, out128)\n",
    "\n",
    "        #Layer 4 : up ( 3 conv layers deep)\n",
    "        output = self.up128(output, out64)\n",
    "        \n",
    "        #Layer 3 : up ( 3 conv layers deep)\n",
    "        output = self.up64(output, out32)\n",
    "        \n",
    "        #Layer 2 : up ( 2 conv layers deep)\n",
    "        output = self.up32(output, out16)\n",
    "        \n",
    "        #Layer 1 : out\n",
    "        output = self.output(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VNet(elu=False, nll=False)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network:  45603451\n"
     ]
    }
   ],
   "source": [
    "n_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print('Number of parameters in network: ', n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder that contains folders of segmentation data\n",
    "PATH = \"data/TrainingDataset_MSSEG/\"\n",
    "# Takes all folders in the path \n",
    "PATH = PATH + \"*/\"\n",
    "image_paths = []\n",
    "mask_paths = []\n",
    "\n",
    "block_size = (32,32,32)\n",
    "\n",
    "directory_paths = glob(PATH)\n",
    "for path in directory_paths:\n",
    "    # Load all the paths for each Flair set of data (1 Flair data and all its segmentation paths)\n",
    "    flair_path = path + '3DFLAIR.nii.gz'\n",
    "    seg1_path = path + 'ManualSegmentation_1.nii.gz'\n",
    "    seg2_path = path + 'ManualSegmentation_2.nii.gz'\n",
    "    seg3_path = path + 'ManualSegmentation_3.nii.gz'\n",
    "    seg4_path = path + 'ManualSegmentation_4.nii.gz'\n",
    "    seg5_path = path + 'ManualSegmentation_5.nii.gz'\n",
    "    seg6_path = path + 'ManualSegmentation_6.nii.gz'\n",
    "    seg7_path = path + 'ManualSegmentation_7.nii.gz'\n",
    "    image_paths.extend([flair_path,flair_path,flair_path,flair_path,flair_path,flair_path,flair_path])\n",
    "    mask_paths.extend([seg1_path,seg2_path,seg3_path,seg4_path,seg5_path,seg6_path,seg7_path])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(image_paths, mask_paths, train_size):\n",
    "    \n",
    "    len_data = len(image_paths)\n",
    "    print('total len:', len_data)\n",
    "\n",
    "    img_mask_list = []\n",
    "    \n",
    "    for i in range(len_data):\n",
    "        img_mask_list.append((image_paths[i], mask_paths[i]))\n",
    "        \n",
    "    train_img_mask_paths = img_mask_list[:int(len_data*train_size)] \n",
    "    val_img_mask_paths = img_mask_list[int(len_data*train_size):]\n",
    "    \n",
    "    return train_img_mask_paths, val_img_mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding(data, block_size):\n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[0]/block_size[0])\n",
    "    #Calculate required padding size \n",
    "    pad_val_c = (block_size[0] * ceil_val) - data.shape[0]\n",
    "    \n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[1]/block_size[1])\n",
    "    #Calculate required padding size\n",
    "    pad_val_h = (block_size[1] * ceil_val) - data.shape[1]\n",
    "    \n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[2]/block_size[2])\n",
    "    # Calculate required padding size\n",
    "    pad_val_w = (block_size[2] * ceil_val) - data.shape[2]\n",
    "    \n",
    "    # Constant padding\n",
    "    data = np.pad(data, ((0,pad_val_c),(0,pad_val_h),(0,pad_val_w)), 'constant')\n",
    "    #data = np.array(data, dtype=np.int16)\n",
    "    \n",
    "    #changed dtype to float\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_data_blocks(data, block_size ):\n",
    "    x = torch.from_numpy(data)\n",
    "    # Add a dimension at 0th position\n",
    "    x = x.unsqueeze(0)\n",
    "    # Kernel Size\n",
    "    kc, kh, kw = block_size[0], block_size[1], block_size[2]\n",
    "    # stride\n",
    "    dc, dh, dw = block_size[0], block_size[1], block_size[2]\n",
    "    patches = x.unfold(1, kc, dc).unfold(2, kh, dh).unfold(3, kw, dw)\n",
    "    unfold_shape = patches.size()\n",
    "    patches = patches.contiguous().view(patches.size(0), -1, kc, kh, kw)\n",
    "    #Return Patches and Unfold Shape\n",
    "    return patches, unfold_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_mask_paths):\n",
    "    img_mask_list = []\n",
    "\n",
    "    for i in tqdm(range(len(image_mask_paths))):\n",
    "        \n",
    "        #load the img and mask\n",
    "        vol = nib.load(image_mask_paths[i][0])\n",
    "        m = nib.load(image_mask_paths[i][1])\n",
    "        \n",
    "        # Get data, normalize the image and pad\n",
    "        img = np.array(vol.get_data(), np.float32) \n",
    "        img = img / np.amax(img)\n",
    "        img_padded = zero_padding(img, block_size)\n",
    "        \n",
    "        mask = np.array(m.get_data(),np.uint8)\n",
    "        mask = mask / np.amax(mask)\n",
    "        mask_padded = zero_padding(mask, block_size)\n",
    "\n",
    "        # Generate data blocks of block_size\n",
    "        img_blocks, unfold_shape_img = get_data_blocks(data = img_padded, block_size = block_size)\n",
    "        mask_blocks, unfold_shape_mask = get_data_blocks(data = mask_padded, block_size = block_size)\n",
    "\n",
    "        img_array = img_blocks.numpy()\n",
    "        mask_array = mask_blocks.numpy()\n",
    "\n",
    "        for i in range(len(img_array[0])):\n",
    "            if np.sum(mask_array[0][i]) !=0:\n",
    "                img_mask_list.append((img_array[0][i], mask_array[0][i]))\n",
    "\n",
    "    return img_mask_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total len: 2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.48s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of blocks containing lesion:  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_img_mask_paths, val_img_mask_paths = split_train_val(image_paths[:2], mask_paths[:2], 0.95)\n",
    "print(len(train_img_mask_paths))\n",
    "#print(val_img_mask_paths)\n",
    "\n",
    "#Training:\n",
    "train_img_masks = preprocess_image(train_img_mask_paths)\n",
    "\n",
    "#Validation:\n",
    "val_img_masks = preprocess_image(val_img_mask_paths)\n",
    "\n",
    "print('No. of blocks containing lesion: ',len(train_img_masks))\n",
    "#print(len(val_img_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b1e2ff1bd30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Image and mask alignment\n",
    "\n",
    "def show_slices(slices):\n",
    "    \"\"\" Function to display row of image slices \"\"\"\n",
    "    fig, axes = plt.subplots(1, len(slices), figsize=(8,8))\n",
    "    for i, slc in enumerate(slices):\n",
    "        axes[i].imshow(slc.T, cmap=\"gray\", origin=\"lower\")\n",
    "\n",
    "# for i in range(1):\n",
    "#     for j in range(len(train_img_masks[i][0][0][0])):\n",
    "#         show_slices([train_img_masks[i][0][j ,:, :], train_img_masks[i][1][j, :, :]])\n",
    "\n",
    "show_slices([train_img_masks[0][0][10 ,:, :], train_img_masks[0][1][10, :, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(32, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "train_img_masks_1 = [(train_img_masks[0][0], train_img_masks[0][1])]\n",
    "print(len(train_img_masks_1))\n",
    "print(train_img_masks_1[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image max value:  0.621622\n",
      "Input mask max value:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Input image max value: ',np.amax(train_img_masks[0][0]))\n",
    "print('Input mask max value: ',np.amax(train_img_masks[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Convert ndarrays in sample to Tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['img'], sample['label']\n",
    "        image = image[None,:,:]\n",
    "        label = label[None,:,:]\n",
    "\n",
    "        return {'img': torch.from_numpy(image.copy()).type(torch.FloatTensor),\n",
    "                'label': torch.from_numpy(label.copy()).type(torch.FloatTensor)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_masks, transforms=None):\n",
    "\n",
    "        self.image_masks = image_masks\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):  # return count of sample we have\n",
    "\n",
    "        return len(self.image_masks)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = self.image_masks[index][0] # H, W, C\n",
    "        mask = self.image_masks[index][1]\n",
    "\n",
    "#       image = np.transpose(image, axes=[2, 0, 1]) # C, H, W\n",
    "\n",
    "        sample = {'img': image, 'label': mask}\n",
    "\n",
    "        if transforms:\n",
    "            sample = self.transforms(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "train_dataset = CustomDataset(train_img_masks_1, transforms=transforms.Compose([ToTensor()]))\n",
    "val_dataset = CustomDataset(val_img_masks, transforms=transforms.Compose([ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dice coefficient \n",
    "class DiceCoeff(Function):\n",
    "    \"\"\"Dice coeff for one pair of input image and target image\"\"\"\n",
    "    def forward(self, prediction, target):\n",
    "        self.save_for_backward(prediction, target)\n",
    "        eps = 0.0001 \n",
    "        A = prediction.view(-1)\n",
    "        B = target.view(-1)\n",
    "        inter = torch.dot(A.float(),B.float())\n",
    "        union = torch.sum(A.float()) + torch.sum(B.float()) - inter + eps\n",
    "        d = inter / union\n",
    "        print('d: ',d)\n",
    "        return d\n",
    "\n",
    "#dice coefficients for batches\n",
    "def dice_coeff(prediction, target):\n",
    "    \"\"\"Dice coeff for batches\"\"\"\n",
    "    s = torch.FloatTensor(1).zero_()\n",
    "    \n",
    "    for i, (a,b) in enumerate(zip(prediction, target)):\n",
    "        s += DiceCoeff().forward(a,b)\n",
    "    s = s / (i + 1)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, dataset):\n",
    "    # set net mode to evaluation\n",
    "    net.eval()\n",
    "    tot = 0\n",
    "    print('Validation began')\n",
    "    print('val len: ', len(dataset))\n",
    "    print(next(net.parameters()).is_cuda)\n",
    "    for i, b in enumerate(dataset):\n",
    "        img = b['img'].to(device)\n",
    "        B = img.shape[0]\n",
    "        true_mask = b['label'].to(device)\n",
    "\n",
    "        # Feed the image to the network to get predicted mask\n",
    "        mask_pred = net.forward(img.float())\n",
    "        print('predicted')\n",
    "        \n",
    "        # For all pixels in predicted mask, set them to 1 if larger than 0.5. Otherwise set them to 0\n",
    "        mask_pred = mask_pred > 0.5\n",
    "        \n",
    "        tot += dice_coeff(true_mask,mask_pred.numpy())\n",
    "        print('tot: ',tot)\n",
    "        #tot += dice_coeff(true_mask,mask_pred)\n",
    "\n",
    "    print('Validation done!')\n",
    "    return tot / (i + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.644084\n",
      "Epoch finished ! Loss: 0.6440840363502502\n",
      "Checkpoint 1 saved !\n",
      "Starting epoch 2/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.643812\n",
      "Epoch finished ! Loss: 0.6438117027282715\n",
      "Checkpoint 2 saved !\n",
      "Starting epoch 3/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.643294\n",
      "Epoch finished ! Loss: 0.6432941555976868\n",
      "Checkpoint 3 saved !\n",
      "Starting epoch 4/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.642556\n",
      "Epoch finished ! Loss: 0.6425559520721436\n",
      "Checkpoint 4 saved !\n",
      "Starting epoch 5/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.641620\n",
      "Epoch finished ! Loss: 0.6416200399398804\n",
      "Checkpoint 5 saved !\n",
      "Starting epoch 6/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.640507\n",
      "Epoch finished ! Loss: 0.6405065655708313\n",
      "Checkpoint 6 saved !\n",
      "Starting epoch 7/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.639235\n",
      "Epoch finished ! Loss: 0.639235258102417\n",
      "Checkpoint 7 saved !\n",
      "Starting epoch 8/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.637823\n",
      "Epoch finished ! Loss: 0.6378233432769775\n",
      "Checkpoint 8 saved !\n",
      "Starting epoch 9/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.636286\n",
      "Epoch finished ! Loss: 0.636285662651062\n",
      "Checkpoint 9 saved !\n",
      "Starting epoch 10/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.634636\n",
      "Epoch finished ! Loss: 0.6346361637115479\n",
      "Checkpoint 10 saved !\n",
      "Starting epoch 11/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.632888\n",
      "Epoch finished ! Loss: 0.6328876614570618\n",
      "Checkpoint 11 saved !\n",
      "Starting epoch 12/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.631052\n",
      "Epoch finished ! Loss: 0.6310524940490723\n",
      "Checkpoint 12 saved !\n",
      "Starting epoch 13/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.629141\n",
      "Epoch finished ! Loss: 0.6291407346725464\n",
      "Checkpoint 13 saved !\n",
      "Starting epoch 14/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.627161\n",
      "Epoch finished ! Loss: 0.6271610856056213\n",
      "Checkpoint 14 saved !\n",
      "Starting epoch 15/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.625123\n",
      "Epoch finished ! Loss: 0.6251228451728821\n",
      "Checkpoint 15 saved !\n",
      "Starting epoch 16/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.623034\n",
      "Epoch finished ! Loss: 0.6230340003967285\n",
      "Checkpoint 16 saved !\n",
      "Starting epoch 17/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.620903\n",
      "Epoch finished ! Loss: 0.6209031343460083\n",
      "Checkpoint 17 saved !\n",
      "Starting epoch 18/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.618733\n",
      "Epoch finished ! Loss: 0.6187331676483154\n",
      "Checkpoint 18 saved !\n",
      "Starting epoch 19/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.616528\n",
      "Epoch finished ! Loss: 0.6165275573730469\n",
      "Checkpoint 19 saved !\n",
      "Starting epoch 20/20.\n",
      "train len:  1\n",
      "0.0000 --- loss: 0.614292\n",
      "Epoch finished ! Loss: 0.6142916083335876\n",
      "Checkpoint 20 saved !\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "epochs = 20 # e.g. 10, or more until dice converge\n",
    "batch_size = 1 # e.g. 16\n",
    "lr = 0.001        # e.g. 0.01, 0.00001\n",
    "N_train = len(train_img_masks_1)\n",
    "model_save_path = '/scratch/srm714/data/model/'  # directory to same the model after each epoch.\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(),lr = lr,momentum=0.90, weight_decay=0.0005)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "net.to(device)\n",
    "\n",
    "# Start training\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}/{}.'.format(epoch + 1, epochs))\n",
    "    net.train()\n",
    "    # Reload images and masks for training and validation and perform random shuffling at the begining of each epoch\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    print('train len: ', len(train_loader))\n",
    "\n",
    "    for i, b in enumerate(train_loader):\n",
    "        # Get images and masks from each batch\n",
    "        imgs = b['img']\n",
    "        true_masks = b['label']\n",
    "        \n",
    "        imgs = imgs.to(device)\n",
    "        true_masks = true_masks.to(device)\n",
    "        \n",
    "\n",
    "        # Feed your images into the network\n",
    "        masks_pred = net.forward(imgs.float())\n",
    "        \n",
    "        true_masks_flat = true_masks.view(-1)\n",
    "        masks_pred_flat = masks_pred.view(-1)\n",
    "\n",
    "        # Calculate the loss by comparing the predicted masks vector and true masks vector\n",
    "        # And sum the losses together\n",
    "        loss = criterion(masks_pred_flat,true_masks_flat.float())\n",
    "        epoch_loss += loss.item()\n",
    "        if count % 50 == 0:\n",
    "            print('{0:.4f} --- loss: {1:.6f}'.format(i * batch_size / N_train, loss.item()))\n",
    "        count = count + 1\n",
    "        # optimizer.zero_grad() clears x.grad for every parameter x in the optimizer.\n",
    "        # It’s important to call this before loss.backward(), otherwise you’ll accumulate the gradients from multiple passes.\n",
    "        optimizer.zero_grad()\n",
    "        # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "        # These are accumulated into x.grad for every parameter x\n",
    "        loss.backward()\n",
    "        # optimizer.step updates the value of x using the gradient x.grad.\n",
    "        optimizer.step()\n",
    "    print('Epoch finished ! Loss: {}'.format(epoch_loss / (i+1)))\n",
    "\n",
    "    # Perform validation with eval_net() on the validation data\n",
    "    #val_dice = eval_net(net,val_loader)\n",
    "    #print('Validation Dice Coeff: {}'.format(val_dice))\n",
    "    \n",
    "    # Save the model after each epoch\n",
    "    if os.path.isdir(model_save_path):\n",
    "        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    else:\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    print('Checkpoint {} saved !'.format(epoch + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VNet(\n",
       "  (input): input_layer(\n",
       "    (conv): Conv3d(1, 16, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "    (relu): PReLU(num_parameters=16)\n",
       "    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (down32): down_layer(\n",
       "    (down_conv): Conv3d(16, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=32)\n",
       "    (layers): Sequential(\n",
       "      (0): single_conv(\n",
       "        (relu): PReLU(num_parameters=32)\n",
       "        (conv): Conv3d(32, 32, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down64): down_layer(\n",
       "    (down_conv): Conv3d(32, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=64)\n",
       "    (layers): Sequential(\n",
       "      (0): single_conv(\n",
       "        (relu): PReLU(num_parameters=64)\n",
       "        (conv): Conv3d(64, 64, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): single_conv(\n",
       "        (relu): PReLU(num_parameters=64)\n",
       "        (conv): Conv3d(64, 64, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down128): down_layer(\n",
       "    (down_conv): Conv3d(64, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=128)\n",
       "    (layers): Sequential(\n",
       "      (0): single_conv(\n",
       "        (relu): PReLU(num_parameters=128)\n",
       "        (conv): Conv3d(128, 128, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): single_conv(\n",
       "        (relu): PReLU(num_parameters=128)\n",
       "        (conv): Conv3d(128, 128, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): single_conv(\n",
       "        (relu): PReLU(num_parameters=128)\n",
       "        (conv): Conv3d(128, 128, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down256): down_layer(\n",
       "    (down_conv): Conv3d(128, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): PReLU(num_parameters=256)\n",
       "    (layers): Sequential(\n",
       "      (0): single_conv(\n",
       "        (relu): PReLU(num_parameters=256)\n",
       "        (conv): Conv3d(256, 256, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): single_conv(\n",
       "        (relu): PReLU(num_parameters=256)\n",
       "        (conv): Conv3d(256, 256, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up256): up_layer(\n",
       "    (up_conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): PReLU(num_parameters=128)\n",
       "    (relu2): PReLU(num_parameters=256)\n",
       "    (layers): Sequential(\n",
       "      (0): single_conv(\n",
       "        (relu): PReLU(num_parameters=256)\n",
       "        (conv): Conv3d(256, 256, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): single_conv(\n",
       "        (relu): PReLU(num_parameters=256)\n",
       "        (conv): Conv3d(256, 256, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up128): up_layer(\n",
       "    (up_conv): ConvTranspose3d(256, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): PReLU(num_parameters=64)\n",
       "    (relu2): PReLU(num_parameters=128)\n",
       "    (layers): Sequential(\n",
       "      (0): single_conv(\n",
       "        (relu): PReLU(num_parameters=128)\n",
       "        (conv): Conv3d(128, 128, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): single_conv(\n",
       "        (relu): PReLU(num_parameters=128)\n",
       "        (conv): Conv3d(128, 128, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up64): up_layer(\n",
       "    (up_conv): ConvTranspose3d(128, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): PReLU(num_parameters=32)\n",
       "    (relu2): PReLU(num_parameters=64)\n",
       "    (layers): Sequential(\n",
       "      (0): single_conv(\n",
       "        (relu): PReLU(num_parameters=64)\n",
       "        (conv): Conv3d(64, 64, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up32): up_layer(\n",
       "    (up_conv): ConvTranspose3d(64, 16, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): PReLU(num_parameters=16)\n",
       "    (relu2): PReLU(num_parameters=32)\n",
       "    (layers): Sequential(\n",
       "      (0): single_conv(\n",
       "        (relu): PReLU(num_parameters=32)\n",
       "        (conv): Conv3d(32, 32, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): output_layer(\n",
       "    (conv1): Conv3d(32, 2, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "    (bn): BatchNorm3d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv3d(2, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (relu1): PReLU(num_parameters=2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('/scratch/srm714/data/model/Brain_Seg_Epoch31.pth'))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(net,full_img,out_threshold=0.5):\n",
    "    # set the mode of your network to evaluation\n",
    "    net.eval()\n",
    "\n",
    "    X_img = torch.from_numpy(full_img).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        output_img = net(X_img.float())\n",
    "        out_probs = output_img.squeeze(0).squeeze(0)\n",
    "        out_mask_np = (out_probs>out_threshold).cpu().numpy().astype('uint8')\n",
    "\n",
    "    return out_mask_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(blocks, unfold_shape):\n",
    "\n",
    "    blocks_orig = blocks.view(unfold_shape)\n",
    "    output_c = unfold_shape[1] * unfold_shape[4]\n",
    "    output_h = unfold_shape[2] * unfold_shape[5]\n",
    "    output_w = unfold_shape[3] * unfold_shape[6]\n",
    "    blocks_orig = blocks_orig.permute(0, 1, 4, 2, 5, 3, 6).contiguous()\n",
    "    blocks_orig = blocks_orig.view(1, output_c, output_h, output_w)\n",
    "    # Remove the dimension at 0th position and convert to numpy\n",
    "    blocks_orig = blocks_orig.squeeze(0).detach().numpy()\n",
    "    return blocks_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the same training block for prediction \n",
    "\n",
    "mask_pred = predict_img(net=net,full_img=train_img_masks_1[0][0], out_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b1e2e2d6588>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b1e2e2d64e0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_slices([train_img_masks_1[0][0][10,:,:], train_img_masks_1[0][1][10,:,:]])\n",
    "show_slices([train_img_masks_1[0][0][10,:,:], mask_pred[10,:,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
