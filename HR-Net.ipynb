{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uu_LsonfD3eY"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import logging\n",
    "import pickle\n",
    "import yaml\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Function, Variable\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUqtyCgmD3ec"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ajrw4zvAD3ef",
    "outputId": "782c74e4-90d1-475c-c5da-ebbd5d909d89"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_device_name() missing 1 required positional argument: 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5717225dc04e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_device_name() missing 1 required positional argument: 'device'"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled = False\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "uakEcW1TD3ei",
    "outputId": "19aa2101-e650-49b5-cdc1-4915d0c273cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices  1\n",
      "Active CUDA Device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HJGcohv0D3ek"
   },
   "outputs": [],
   "source": [
    "BN_MOMENTUM = 0.1\n",
    "def conv3x3(in_chan, out_chan, stride=1):\n",
    "    return nn.Conv3d(in_chan, out_chan, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rtCt1fmD3em"
   },
   "outputs": [],
   "source": [
    "class Conv_Block(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_chan, out_chan, stride=1, downsample=None):\n",
    "        super(Conv_Block, self).__init__()\n",
    "        self.conv1 = conv3x3(in_chan, out_chan, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(out_chan, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_chan, out_chan)\n",
    "        self.bn2 = nn.BatchNorm3d(out_chan, momentum=BN_MOMENTUM)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inter_conn(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_chan, out_chan, stride=1, downsample=None):\n",
    "        super(Inter_conn, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_chan, out_chan, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(out_chan, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv3d(out_chan, out_chan, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(out_chan, momentum=BN_MOMENTUM)\n",
    "        self.conv3 = nn.Conv3d(out_chan, out_chan * self.expansion, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(out_chan * self.expansion,\n",
    "                                  momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A6iwhyXDD3es"
   },
   "outputs": [],
   "source": [
    "class Three_D_HRModule(nn.Module):\n",
    "    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,\n",
    "                 num_channels, fuse_method, multi_scale_output=True):\n",
    "        super(Three_D_HRModule, self).__init__()\n",
    "        \n",
    "\n",
    "        self.num_inchannels = num_inchannels\n",
    "        self.fuse_method = fuse_method\n",
    "        self.num_branches = num_branches\n",
    "\n",
    "        self.multi_scale_output = multi_scale_output\n",
    "\n",
    "        self.branches = self.layers(\n",
    "            num_branches, blocks, num_blocks, num_channels)\n",
    "        self.fuse_layers = self.fuse_layers()\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "    def single_block(self, branch_index, block, num_blocks, num_channels,\n",
    "                         stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or \\\n",
    "           self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(\n",
    "                    self.num_inchannels[branch_index],\n",
    "                    num_channels[branch_index] * block.expansion,\n",
    "                    kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm3d(\n",
    "                    num_channels[branch_index] * block.expansion,\n",
    "                    momentum=BN_MOMENTUM\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.num_inchannels[branch_index],\n",
    "                num_channels[branch_index],\n",
    "                stride,\n",
    "                downsample\n",
    "            )\n",
    "        )\n",
    "        self.num_inchannels[branch_index] = \\\n",
    "            num_channels[branch_index] * block.expansion\n",
    "        for i in range(1, num_blocks[branch_index]):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.num_inchannels[branch_index],\n",
    "                    num_channels[branch_index]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def layers(self, num_branches, block, num_blocks, num_channels):\n",
    "        branches = []\n",
    "\n",
    "        for i in range(num_branches):\n",
    "            branches.append(\n",
    "                self.single_block(i, block, num_blocks, num_channels)\n",
    "            )\n",
    "\n",
    "        return nn.ModuleList(branches)\n",
    "\n",
    "    def fuse_layers(self):\n",
    "        if self.num_branches == 1:\n",
    "            return None\n",
    "\n",
    "        num_branches = self.num_branches\n",
    "        num_inchannels = self.num_inchannels\n",
    "        fuse_layers = []\n",
    "        for i in range(num_branches if self.multi_scale_output else 1):\n",
    "            fuse_layer = []\n",
    "            for j in range(num_branches):\n",
    "                if j > i:\n",
    "                    fuse_layer.append(\n",
    "                        nn.Sequential(\n",
    "                            nn.Conv3d(\n",
    "                                num_inchannels[j],\n",
    "                                num_inchannels[i],\n",
    "                                1, 1, 0, bias=False\n",
    "                            ),\n",
    "                            nn.BatchNorm3d(num_inchannels[i]),\n",
    "                            nn.Upsample(scale_factor=2**(j-i), mode='nearest')\n",
    "                        )\n",
    "                    )\n",
    "                elif j == i:\n",
    "                    fuse_layer.append(None)\n",
    "                else:\n",
    "                    conv3x3s = []\n",
    "                    for k in range(i-j):\n",
    "                        if k == i - j - 1:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[i]\n",
    "                            conv3x3s.append(\n",
    "                                nn.Sequential(\n",
    "                                    nn.Conv3d(\n",
    "                                        num_inchannels[j],\n",
    "                                        num_outchannels_conv3x3,\n",
    "                                        3, 2, 1, bias=False\n",
    "                                    ),\n",
    "                                    nn.BatchNorm3d(num_outchannels_conv3x3)\n",
    "                                )\n",
    "                            )\n",
    "                        else:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[j]\n",
    "                            conv3x3s.append(\n",
    "                                nn.Sequential(\n",
    "                                    nn.Conv3d(\n",
    "                                        num_inchannels[j],\n",
    "                                        num_outchannels_conv3x3,\n",
    "                                        3, 2, 1, bias=False\n",
    "                                    ),\n",
    "                                    nn.BatchNorm3d(num_outchannels_conv3x3),\n",
    "                                    nn.ReLU(True)\n",
    "                                )\n",
    "                            )\n",
    "                    fuse_layer.append(nn.Sequential(*conv3x3s))\n",
    "            fuse_layers.append(nn.ModuleList(fuse_layer))\n",
    "\n",
    "        return nn.ModuleList(fuse_layers)\n",
    "\n",
    "    def get_count_inchannels(self):\n",
    "        return self.num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.num_branches == 1:\n",
    "            return [self.branches[0](x[0])]\n",
    "\n",
    "        for i in range(self.num_branches):\n",
    "            x[i] = self.branches[i](x[i])\n",
    "\n",
    "        x_fuse = []\n",
    "\n",
    "        for i in range(len(self.fuse_layers)):\n",
    "            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n",
    "            for j in range(1, self.num_branches):\n",
    "                if i == j:\n",
    "                    y = y + x[j]\n",
    "                else:\n",
    "                    y = y + self.fuse_layers[i][j](x[j])\n",
    "            x_fuse.append(self.relu(y))\n",
    "\n",
    "        return x_fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIk-FJiHD3ew"
   },
   "outputs": [],
   "source": [
    "class Three_D_HRNet(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        self.in_chan = 64\n",
    "        extra = cfg['MODEL']['EXTRA']\n",
    "        super(Three_D_HRNet, self).__init__()\n",
    "\n",
    "        # stem net\n",
    "        self.conv1 = nn.Conv3d(1, 64, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv3d(64, 64, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(64, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(Inter_conn, 64, 4)\n",
    "\n",
    "        self.stage2_cfg = extra['STAGE2']\n",
    "        num_channels = [32, 64]\n",
    "        block = Conv_Block\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))\n",
    "        ]\n",
    "        self.transition1 = self._make_transition_layer([256], num_channels)\n",
    "        self.stage2, pre_stage_channels = self._make_stage(\n",
    "            self.stage2_cfg, num_channels)\n",
    "\n",
    "        self.stage3_cfg = extra['STAGE3']\n",
    "        num_channels = [32, 64, 128]\n",
    "        block = Conv_Block\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))\n",
    "        ]\n",
    "        self.transition2 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage3, pre_stage_channels = self._make_stage(\n",
    "            self.stage3_cfg, num_channels)\n",
    "\n",
    "        self.stage4_cfg = extra['STAGE4']\n",
    "        num_channels = [32, 64, 128, 256]\n",
    "        block = Conv_Block\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))\n",
    "        ]\n",
    "        self.transition3 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage4, pre_stage_channels = self._make_stage(\n",
    "            self.stage4_cfg, num_channels, multi_scale_output=False)\n",
    "\n",
    "        self.final_layer_1 = nn.Conv3d(\n",
    "            in_channels=pre_stage_channels[0],\n",
    "            out_channels=2,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.final_layer_2 = nn.Conv3d(\n",
    "            in_channels=2,\n",
    "            out_channels=1,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "        self.sigmoid = F.sigmoid\n",
    "\n",
    "\n",
    "    def _make_transition_layer(\n",
    "            self, num_channels_pre_layer, num_channels_cur_layer):\n",
    "        num_branches_cur = len(num_channels_cur_layer)\n",
    "        num_branches_pre = len(num_channels_pre_layer)\n",
    "\n",
    "        transition_layers = []\n",
    "        for i in range(num_branches_cur):\n",
    "            if i < num_branches_pre:\n",
    "                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n",
    "                    transition_layers.append(\n",
    "                        nn.Sequential(\n",
    "                            nn.Conv3d(\n",
    "                                num_channels_pre_layer[i],\n",
    "                                num_channels_cur_layer[i],\n",
    "                                3, 1, 1, bias=False\n",
    "                            ),\n",
    "                            nn.BatchNorm3d(num_channels_cur_layer[i]),\n",
    "                            nn.ReLU(inplace=True)\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    transition_layers.append(None)\n",
    "            else:\n",
    "                conv3x3s = []\n",
    "                for j in range(i+1-num_branches_pre):\n",
    "                    inchannels = num_channels_pre_layer[-1]\n",
    "                    outchannels = num_channels_cur_layer[i] \\\n",
    "                        if j == i-num_branches_pre else inchannels\n",
    "                    conv3x3s.append(\n",
    "                        nn.Sequential(\n",
    "                            nn.Conv3d(\n",
    "                                inchannels, outchannels, 3, 2, 1, bias=False\n",
    "                            ),\n",
    "                            nn.BatchNorm3d(outchannels),\n",
    "                            nn.ReLU(inplace=True)\n",
    "                        )\n",
    "                    )\n",
    "                transition_layers.append(nn.Sequential(*conv3x3s))\n",
    "\n",
    "        return nn.ModuleList(transition_layers)\n",
    "\n",
    "    def _make_layer(self, block, out_chan, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_chan != out_chan * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(\n",
    "                    self.in_chan, out_chan * block.expansion,\n",
    "                    kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm3d(out_chan * block.expansion, momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_chan, out_chan, stride, downsample))\n",
    "        self.in_chan = out_chan * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.in_chan, out_chan))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_stage(self, layer_config, num_inchannels,\n",
    "                    multi_scale_output=True):\n",
    "        num_modules = layer_config['NUM_MODULES']\n",
    "        num_branches = layer_config['NUM_BRANCHES']\n",
    "        num_blocks = layer_config['NUM_BLOCKS']\n",
    "        num_channels = layer_config['NUM_CHANNELS']\n",
    "        block = Conv_Block\n",
    "        fuse_method = layer_config['FUSE_METHOD']\n",
    "\n",
    "        modules = []\n",
    "        for i in range(num_modules):\n",
    "            # multi_scale_output is only used last module\n",
    "            if not multi_scale_output and i == num_modules - 1:\n",
    "                reset_multi_scale_output = False\n",
    "            else:\n",
    "                reset_multi_scale_output = True\n",
    "\n",
    "            modules.append(\n",
    "                Three_D_HRModule(\n",
    "                    num_branches,\n",
    "                    block,\n",
    "                    num_blocks,\n",
    "                    num_inchannels,\n",
    "                    num_channels,\n",
    "                    fuse_method,\n",
    "                    reset_multi_scale_output\n",
    "                )\n",
    "            )\n",
    "            num_inchannels = modules[-1].get_count_inchannels()\n",
    "\n",
    "        return nn.Sequential(*modules), num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(2):\n",
    "            if self.transition1[i] is not None:\n",
    "                x_list.append(self.transition1[i](x))\n",
    "            else:\n",
    "                x_list.append(x)\n",
    "        y_list = self.stage2(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(3):\n",
    "            if self.transition2[i] is not None:\n",
    "                x_list.append(self.transition2[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        y_list = self.stage3(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(4):\n",
    "            if self.transition3[i] is not None:\n",
    "                x_list.append(self.transition3[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        y_list = self.stage4(x_list)\n",
    "\n",
    "        x = self.final_layer_1(y_list[0])\n",
    "        x = self.final_layer_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        #print(x.size())\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nqg1lMhAD3ey"
   },
   "outputs": [],
   "source": [
    "config = {'MODEL' : \n",
    "                {'EXTRA': \n",
    "                        {'STAGE2': {'NUM_CHANNELS': [32, 64], 'NUM_MODULES': 1, 'FUSE_METHOD': 'SUM', 'NUM_BRANCHES': 2, 'NUM_BLOCKS': [4, 4]}, \n",
    "\n",
    "                        'STAGE4': {'NUM_CHANNELS': [32, 64, 128, 256], 'NUM_MODULES': 3, 'FUSE_METHOD': 'SUM', 'NUM_BRANCHES': 4, 'NUM_BLOCKS': [4, 4, 4, 4]}, \n",
    "\n",
    "                        'STAGE3': {'NUM_CHANNELS': [32, 64, 128], 'NUM_MODULES': 4, 'FUSE_METHOD': 'SUM',  'NUM_BRANCHES': 3, 'NUM_BLOCKS': [4, 4, 4]}}}}\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "V59ZYrQmD3e0",
    "outputId": "74931a1b-46ba-42e1-b445-41e019f147ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network:  84791749\n"
     ]
    }
   ],
   "source": [
    "net = Three_D_HRNet(config)\n",
    "net = nn.DataParallel(net)\n",
    "n_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print('Number of parameters in network: ', n_params)\n",
    "#2d : 28536113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ueUxUHzSEdrk",
    "outputId": "c2adccf1-9af8-4ce7-ba81-78f7e80676ce"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_imBvAxzD3e2"
   },
   "outputs": [],
   "source": [
    "# Path to the folder that contains folders of segmentation data\n",
    "#train_path = \"C:\\\\SSRM\\\\Unprocessed training dataset\\\\TrainingDataset_MSSEG\\\\train\\\\*\\\\\"\n",
    "#test_path = \"C:\\\\SSRM\\\\Unprocessed training dataset\\\\TrainingDataset_MSSEG\\\\test\\\\*\\\\\"\n",
    "#val_path = \"C:\\\\SSRM\\\\Unprocessed training dataset\\\\TrainingDataset_MSSEG\\\\val\\\\*\\\\\"\n",
    "\n",
    "train_path = \"data/Preprocessed/train/*/\"\n",
    "test_path = \"data/Preprocessed/test/*/\"\n",
    "val_path = \"data/Preprocessed/validation/*/\"\n",
    "\n",
    "train_image_mask_paths = []\n",
    "test_image_mask_paths = []\n",
    "val_image_mask_paths = []\n",
    "\n",
    "\n",
    "block_size = (16,16,16)\n",
    "\n",
    "#Load training images\n",
    "directory_paths = glob(train_path)\n",
    "for path in directory_paths:\n",
    "    # Load all the paths for each Flair set of data (1 Flair data and all its segmentation paths)\n",
    "    flair_path = path + 'FLAIR_preprocessed.nii.gz'\n",
    "    seg_path = path + 'Consensus.nii.gz'\n",
    "    train_image_mask_paths.append((flair_path,seg_path))\n",
    "    \n",
    "directory_paths = glob(test_path)\n",
    "for path in directory_paths:\n",
    "    # Load all the paths for each Flair set of data (1 Flair data and all its segmentation paths)\n",
    "    flair_path = path + 'FLAIR_preprocessed.nii.gz'\n",
    "    seg_path = path + 'Consensus.nii.gz'\n",
    "    test_image_mask_paths.append((flair_path,seg_path))\n",
    "    \n",
    "directory_paths = glob(val_path)\n",
    "for path in directory_paths:\n",
    "    # Load all the paths for each Flair set of data (1 Flair data and all its segmentation paths)\n",
    "    flair_path = path + 'FLAIR_preprocessed.nii.gz'\n",
    "    seg_path = path + 'Consensus.nii.gz'\n",
    "    val_image_mask_paths.append((flair_path,seg_path))\n",
    "\n",
    "#train_image_mask_paths = train_image_mask_paths[:1]\n",
    "#test_image_mask_paths = test_image_mask_paths[:1]\n",
    "val_image_mask_paths = val_image_mask_paths[:1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4otHgcMD3e6"
   },
   "outputs": [],
   "source": [
    "def zero_padding(data, block_size):\n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[0]/block_size[0])\n",
    "    #Calculate required padding size \n",
    "    pad_val_c = (block_size[0] * ceil_val) - data.shape[0]\n",
    "    \n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[1]/block_size[1])\n",
    "    #Calculate required padding size\n",
    "    pad_val_h = (block_size[1] * ceil_val) - data.shape[1]\n",
    "    \n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[2]/block_size[2])\n",
    "    # Calculate required padding size\n",
    "    pad_val_w = (block_size[2] * ceil_val) - data.shape[2]\n",
    "    \n",
    "    # Constant padding\n",
    "    #data = data.numpy()\n",
    "    data = np.pad(data, ((0,pad_val_c),(0,pad_val_h),(0,pad_val_w)), 'constant')\n",
    "    #data = np.array(data, dtype=np.int16)\n",
    "    \n",
    "    #changed dtype to float\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_data_blocks(data, block_size ):\n",
    "    x = torch.from_numpy(data)\n",
    "    # Add a dimension at 0th position\n",
    "    x = x.unsqueeze(0)\n",
    "    # Kernel Size\n",
    "    kc, kh, kw = block_size[0], block_size[1], block_size[2]\n",
    "    # stride\n",
    "    dc, dh, dw = block_size[0], block_size[1], block_size[2]\n",
    "    patches = x.unfold(1, kc, dc).unfold(2, kh, dh).unfold(3, kw, dw)\n",
    "    unfold_shape = patches.size()\n",
    "    patches = patches.contiguous().view(patches.size(0), -1, kc, kh, kw)\n",
    "    #Return Patches and Unfold Shape\n",
    "    return patches, unfold_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6nPIEz9D3e-"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_mask_paths):\n",
    "    img_mask_list = []\n",
    "\n",
    "    for i in tqdm(range(len(image_mask_paths))):\n",
    "        \n",
    "        #load the img and mask\n",
    "        vol = nib.load(image_mask_paths[i][0])\n",
    "        m = nib.load(image_mask_paths[i][1])\n",
    "        \n",
    "        # Get data, normalize the image and pad\n",
    "        img = np.array(vol.get_data(), np.float32) \n",
    "        img = img / np.amax(img)\n",
    "        img_padded = zero_padding(img, block_size)\n",
    "        \n",
    "        mask = np.array(m.get_data(),np.uint8)\n",
    "        mask = mask / np.amax(mask)\n",
    "        mask_padded = zero_padding(mask, block_size)\n",
    "\n",
    "        # Generate data blocks of block_size\n",
    "        img_blocks, unfold_shape_img = get_data_blocks(data = img_padded, block_size = block_size)\n",
    "        mask_blocks, unfold_shape_mask = get_data_blocks(data = mask_padded, block_size = block_size)\n",
    "\n",
    "        img_array = img_blocks.numpy()\n",
    "        mask_array = mask_blocks.numpy()\n",
    "               \n",
    "        \n",
    "        for i in range(len(img_array[0])):\n",
    "            if np.sum(mask_array[0][i]) !=0:\n",
    "                img_mask_list.append((img_array[0][i], mask_array[0][i]))\n",
    "\n",
    "    return img_mask_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "B41IKdLQD3fA",
    "outputId": "5945363a-0221-4372-ca7d-83b793d7a231"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:14<00:00,  1.58s/it]\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.54s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of blocks containing lesion:  1678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#print(train_image_mask_paths)\n",
    "#Training:\n",
    "train_img_masks = preprocess_image(train_image_mask_paths)\n",
    "\n",
    "#Training:\n",
    "test_img_masks = preprocess_image(test_image_mask_paths)\n",
    "\n",
    "#Validation:\n",
    "val_img_masks = preprocess_image(val_image_mask_paths)\n",
    "\n",
    "print('No. of blocks containing lesion: ',len(train_img_masks))\n",
    "#print(len(val_img_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_un0iZWnD3fE"
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Convert ndarrays in sample to Tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['img'], sample['label']\n",
    "        image = image[None,:,:]\n",
    "        label = label[None,:,:]\n",
    "\n",
    "        return {'img': torch.from_numpy(image.copy()).type(torch.FloatTensor),\n",
    "                'label': torch.from_numpy(label.copy()).type(torch.FloatTensor)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05ctT9BmD3fG"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_masks, transforms=None):\n",
    "\n",
    "        self.image_masks = image_masks\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):  # return count of sample we have\n",
    "\n",
    "        return len(self.image_masks)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = self.image_masks[index][0] # H, W, C\n",
    "        mask = self.image_masks[index][1]\n",
    "\n",
    "#       image = np.transpose(image, axes=[2, 0, 1]) # C, H, W\n",
    "\n",
    "        sample = {'img': image, 'label': mask}\n",
    "\n",
    "        if transforms:\n",
    "            sample = self.transforms(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "train_dataset = CustomDataset(train_img_masks, transforms=transforms.Compose([ToTensor()]))\n",
    "val_dataset = CustomDataset(val_img_masks, transforms=transforms.Compose([ToTensor()]))\n",
    "test_dataset = CustomDataset(test_img_masks, transforms=transforms.Compose([ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I23Ck-nbD3fI"
   },
   "outputs": [],
   "source": [
    "\n",
    "# define dice coefficient \n",
    "class DiceCoeff(Function):\n",
    "    \"\"\"Dice coeff for one pair of input image and target image\"\"\"\n",
    "    def forward(self, prediction, target):\n",
    "        self.save_for_backward(prediction, target)\n",
    "        eps = 0.0001 # in case union = 0\n",
    "        # Calculate intersection and union. \n",
    "        # You can convert the input image into a vector with input.contiguous().view(-1)\n",
    "        # Then use torch.dot(A, B) to calculate the intersection.\n",
    "        A = prediction.view(-1)\n",
    "        B = target.view(-1)\n",
    "        inter = torch.dot(A.float(),B.float())\n",
    "        union = torch.sum(A.float()) + torch.sum(B.float()) - inter + eps\n",
    "        # Calculate DICE \n",
    "        d = inter / union\n",
    "        return d\n",
    "\n",
    "# Calculate dice coefficients for batches\n",
    "def dice_coeff(prediction, target):\n",
    "    \"\"\"Dice coeff for batches\"\"\"\n",
    "    s = torch.FloatTensor(1).zero_()\n",
    "    \n",
    "    # For each pair of input and target, call DiceCoeff().forward(prediction, target) to calculate dice coefficient\n",
    "    # Then average\n",
    "    for i, (a,b) in enumerate(zip(prediction, target)):\n",
    "        s += DiceCoeff().forward(a,b)\n",
    "    s = s / (i + 1)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x8edM4rDD3fK"
   },
   "outputs": [],
   "source": [
    "def eval_net(net, dataset):\n",
    "    # set net mode to evaluation\n",
    "    net.eval()\n",
    "    tot = 0\n",
    "    print('Validation began')\n",
    "    print('val len: ', len(dataset))\n",
    "    #print(next(net.parameters()).is_cuda)\n",
    "    for i, b in enumerate(dataset):\n",
    "        img = b['img'].to(device)\n",
    "        B = img.shape[0]\n",
    "        true_mask = b['label'].to(device)\n",
    "\n",
    "        # Feed the image to the network to get predicted mask\n",
    "        mask_pred = net.forward(img.float())\n",
    "        #print('predicted')\n",
    "        \n",
    "        # For all pixels in predicted mask, set them to 1 if larger than 0.5. Otherwise set them to 0\n",
    "        #mask_pred = mask_pred > 0.5\n",
    "        \n",
    "        # calculate dice_coeff()\n",
    "        # note that you should add all the dice_coeff in validation/testing dataset together\n",
    "        # call dice_coeff() here\n",
    "        masks_probs_flat = mask_pred.view(mask_pred.numel())\n",
    "        true_masks_flat = true_mask.view(true_mask.numel())\n",
    "        \n",
    "        tot += dice_coeff(true_masks_flat,masks_probs_flat)\n",
    "        #print('tot: ',tot)\n",
    "        #tot += dice_coeff(true_mask,mask_pred)\n",
    "        # Return average dice_coeff()\n",
    "    print('Validation done!')\n",
    "    return tot / (i + 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ULcWS3R2D3fM",
    "outputId": "0e4abafa-c90d-4779-fd28-50a6eb61ddae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "smtg_fDpIPhH"
   },
   "outputs": [],
   "source": [
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "#writer = SummaryWriter('/content/gdrive/My Drive/IVP Project/Dataset/runs/hrnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(input, target):\n",
    "    smooth = 1.\n",
    "\n",
    "    iflat = input.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    \n",
    "    return 1 - ((2. * intersection + smooth) /\n",
    "              (iflat.sum() + tflat.sum() + smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "epochs = 1000\n",
    "batch_size = 1 \n",
    "lr = 0.01        \n",
    "N_train = len(train_img_masks)\n",
    "model_save_path = './' #'/content/gdrive/My Drive/IVP Project/Dataset/models/hrnet/'\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = lr, weight_decay=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 100, gamma=0.1)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "net.to(device)\n",
    "loss_graph_values = {}\n",
    "loss_graph_list = []\n",
    "\n",
    "# Start training\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}/{}.'.format(epoch + 1, epochs))\n",
    "    net.train()\n",
    "    # Reload images and masks for training and validation and perform random shuffling at the begining of each epoch\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    #print('train len: ', len(train_loader))\n",
    "    #print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "    for i, b in enumerate(train_loader):\n",
    "        # Get images and masks from each batch\n",
    "        imgs = b['img']\n",
    "        true_masks = b['label']\n",
    "        \n",
    "        imgs = imgs.to(device)\n",
    "        true_masks = true_masks.to(device)\n",
    "        #print('True mask shape: ',true_masks.shape)\n",
    "        \n",
    "        # Feed your images into the network\n",
    "        masks_pred = net.forward(imgs.float())\n",
    "        #print('mask:',masks_pred.shape)\n",
    "        #print('true:',true_masks.shape)\n",
    "        masks_probs = masks_pred[:,0,:,:,:]\n",
    "        masks_probs = masks_probs.unsqueeze(1)\n",
    "\n",
    "        masks_probs_flat = masks_probs.reshape(1,-1)\n",
    "        masks_probs_flat = masks_probs_flat.squeeze()\n",
    "\n",
    "        true_masks_flat = true_masks.reshape(1,-1)\n",
    "        true_masks_flat = true_masks_flat.squeeze()\n",
    "\n",
    "        # Calculate the loss by comparing the predicted masks vector and true masks vector\n",
    "        # And sum the losses together\n",
    "        loss = criterion(masks_probs_flat,true_masks_flat.float())\n",
    "        #loss = dice_loss(masks_probs_flat,true_masks_flat.float())\n",
    "        epoch_loss += loss.item()\n",
    "        if count % 50 == 0:\n",
    "            print('{0:.4f} --- loss: {1:.6f}'.format(i * batch_size / N_train, loss.item()))\n",
    "        count = count + 1\n",
    "        # optimizer.zero_grad() clears x.grad for every parameter x in the optimizer.\n",
    "        # It’s important to call this before loss.backward(), otherwise you’ll accumulate the gradients from multiple passes.\n",
    "        optimizer.zero_grad()\n",
    "        # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "        # These are accumulated into x.grad for every parameter x\n",
    "        loss.backward()\n",
    "        # optimizer.step updates the value of x using the gradient x.grad.\n",
    "        optimizer.step()\n",
    "    print('Epoch finished ! Loss: {}'.format(epoch_loss / i))\n",
    "    loss_graph_values[epoch] = epoch_loss / i\n",
    "    loss_graph_list.append(epoch_loss / i)\n",
    "    #writer.add_scalar('training loss', (epoch_loss / (i+1)), epoch)\n",
    "\n",
    "    # Perform validation with eval_net() on the validation data\n",
    "    #val_dice = eval_net(net,val_loader)\n",
    "    #print('Validation Dice Coeff: {}'.format(val_dice))\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save the model after each epoch\n",
    "    '''if os.path.isdir(model_save_path):\n",
    "        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    else:\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    print('Checkpoint {} saved !'.format(epoch + 1))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if os.path.isdir(model_save_path):\\n    torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\\nelse:\\n        os.makedirs(model_save_path, exist_ok=True)\\n        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\\nprint('Checkpoint {} saved !'.format(epoch + 1))\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''if os.path.isdir(model_save_path):\n",
    "    torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "else:\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "print('Checkpoint {} saved !'.format(epoch + 1))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation began\n",
      "val len:  98\n"
     ]
    }
   ],
   "source": [
    "#net.load_state_dict(torch.load('Brain_Seg_Epoch116.pth'))\n",
    "#val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "val_dice = eval_net(net,val_loader)\n",
    "print('Validation Dice Coeff: {}'.format(val_dice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(net,full_img,out_threshold=0.1):\n",
    "    # set the mode of your network to evaluation\n",
    "    net.eval()\n",
    "\n",
    "    X_img = torch.from_numpy(full_img).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        output_img = net(X_img.float())\n",
    "        out_probs = output_img.squeeze(0).squeeze(0)\n",
    "        out_mask_np = (out_probs>out_threshold).cpu().numpy().astype('uint8')\n",
    "\n",
    "    return out_mask_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(blocks, unfold_shape):\n",
    "\n",
    "    blocks_orig = blocks.view(unfold_shape)\n",
    "    output_c = unfold_shape[1] * unfold_shape[4]\n",
    "    output_h = unfold_shape[2] * unfold_shape[5]\n",
    "    output_w = unfold_shape[3] * unfold_shape[6]\n",
    "    blocks_orig = blocks_orig.permute(0, 1, 4, 2, 5, 3, 6).contiguous()\n",
    "    blocks_orig = blocks_orig.view(1, output_c, output_h, output_w)\n",
    "    # Remove the dimension at 0th position and convert to numpy\n",
    "    blocks_orig = blocks_orig.squeeze(0).detach().numpy()\n",
    "    return blocks_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_masks_1 = [(train_img_masks[0][0], train_img_masks[0][1])]\n",
    "print(len(train_img_masks_1))\n",
    "print(train_img_masks_1[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pred = predict_img(net=net,full_img=train_img_masks_1[0][0], out_threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Image and mask alignment\n",
    "def show_slices(slices):\n",
    "    \"\"\" Function to display row of image slices \"\"\"\n",
    "    fig, axes = plt.subplots(1, len(slices), figsize=(8,8))\n",
    "    for i, slc in enumerate(slices):\n",
    "        axes[i].imshow(slc.T, cmap=\"gray\", origin=\"lower\")\n",
    "\n",
    "for i in range(1):\n",
    "    for j in range(len(train_img_masks[i][0][0][0])):\n",
    "        show_slices([train_img_masks_1[i][0][:, :, j], train_img_masks[i][1][:, :, j], mask_pred[:,:,j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "lists = sorted(loss_graph_values.items()) # sorted by key, return a list of tuples\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "test_dice = eval_net(net,test_loader)\n",
    "print('Test Dice Coeff: {}'.format(test_dice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "HR-Net_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
