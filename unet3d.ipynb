{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Function, Variable\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1660 Ti'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class single_conv(nn.Module):\n",
    "    def __init__(self, inchan, outchan):\n",
    "        super(single_conv, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = nn.Conv3d(inchan, outchan, kernel_size=5, padding=2)\n",
    "        self.bn = nn.BatchNorm3d(outchan)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn(self.conv(x)))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class input_layer(nn.Module):\n",
    "    def __init__(self, inchan, outchan):\n",
    "        super(single_conv, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = nn.Conv3d(inchan, outchan, kernel_size=5, padding=2)\n",
    "        self.bn = nn.BatchNorm3d(outchan)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn(self.conv(x)))\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class down(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(down, self).__init__()\n",
    "        self.down = nn.MaxPool3d((2,2,2)) \n",
    "    def forward(self, x):\n",
    "        x = self.down(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class up(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(up, self).__init__()\n",
    "        self.up = nn.Upsample(scale_factor = 2, mode = 'trilinear') # use nn.Upsample() with mode bilinear\n",
    "    def forward(self, x1, x2): # Takes in smaller x1 and larger x2\n",
    "        # First we upsample x1 to be same size as x2\n",
    "        x1 = self.up(x1)\n",
    "        # This part is tricky so we've completed this\n",
    "        # Notice that x2 and x1 may not have the same spatial size.\n",
    "        # This is because when you downsample old_x2(say 25 by 25), you will get x1(12 by 12)\n",
    "        # Then you perform upsample to x1, you will get new_x1(24 by 24) 3/26/2020 CA04_UNet_TEMPLATEfile:///Users/admin/Downloads/CA04_UNet_TEMPLATE.html 4/29\n",
    "        # You should pad a new row and column so that new_x1 and x2 have the same size.\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        diffZ = x2.size()[4] - x1.size()[4]\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2, diffY // 2, diffY - diffY//2, diffZ // 2, diffZ - diffZ//2))\n",
    "        # Now we concatenat x2 and x1 along channel dimension: torch.cat()\n",
    "        # Note pytorch tensor shape correspond to: (batchsize, channel, x_dim, y_dim)\n",
    "        x = torch.cat((x2,x1),1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        # 1 conv layer\n",
    "        self.conv = nn.Conv3d(in_ch, out_ch, kernel_size = 1)\n",
    "    def forward(self, x):\n",
    "        #x = np.pad(x, ((0,2),(0,2),(0,2)), 'constant')\n",
    "        x = self.conv(x)\n",
    "        # Apply sigmoid activation: torch.sigmoid()\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        ## Define the necessary layers using the classes defined above\n",
    "        self.conv_1_16 = single_conv(1,16)\n",
    "        self.down = down()\n",
    "        self.up = up()\n",
    "        self.conv_16_32 = single_conv(16,32)\n",
    "        self.conv_32_32 = single_conv(32,32)\n",
    "        self.conv_64_16 = single_conv(64,16)\n",
    "        self.conv_32_16 = single_conv(32,16)\n",
    "        self.outconv = outconv(16,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Define forward pass\n",
    "        x1 = self.conv_1_16(x)\n",
    "        #print(x1.shape) \n",
    "        x1d = self.down(x1)\n",
    "        #print(x1d.shape)\n",
    "        x2 = self.conv_16_32(x1d)\n",
    "        #print(x2.shape)\n",
    "        x2d = self.down(x2)\n",
    "        #print(x2d.shape)\n",
    "        x3 = self.conv_32_32(x2d)\n",
    "        #print(x3.shape)\n",
    "        x4 = self.up(x3,x2)\n",
    "        #print(x4.shape)\n",
    "        x5 = self.conv_64_16(x4)\n",
    "        #print(x5.shape)\n",
    "        x6 = self.up(x5,x1)\n",
    "        #print(x6.shape)\n",
    "        x7 = self.conv_32_16(x6)\n",
    "        #print(x7.shape)\n",
    "        x = self.outconv(x7)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet()\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network:  386353\n"
     ]
    }
   ],
   "source": [
    "n_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print('Number of parameters in network: ', n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder that contains folders of segmentation data\n",
    "PATH = \"data/TrainingDataset_MSSEG/*/\"\n",
    "IPATH = \"data/Pre-processed training dataset/*/\"\n",
    "# Takes all folders in the path \n",
    "image_paths = []\n",
    "mask_paths = []\n",
    "\n",
    "block_size = (32,32,32)\n",
    "\n",
    "for path in glob(PATH):\n",
    "    # Load all the paths for each Flair set of data (1 Flair data and all its segmentation paths)\n",
    "    seg1_path = path + 'Consensus.nii.gz'\n",
    "    mask_paths.extend([seg1_path])\n",
    "    \n",
    "for path in glob(IPATH):\n",
    "    flair_path = path + 'FLAIR_preprocessed.nii.gz'\n",
    "    image_paths.extend([flair_path])\n",
    "#print(image_paths)\n",
    "#print(mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(image_paths, mask_paths, train_size):\n",
    "    img_paths_dic = {}\n",
    "    mask_paths_dic = {}\n",
    "    len_data = len(image_paths)\n",
    "    print('total len:', len_data)\n",
    "    p = 0\n",
    "    q = 0\n",
    "    for i in range(len(image_paths)):\n",
    "        img_paths_dic[str(p)+'_'+str(q)] = image_paths[i]\n",
    "        if q==6:\n",
    "            q=0\n",
    "            p=p+1\n",
    "        else:\n",
    "            q=q+1\n",
    "    \n",
    "    p = 0\n",
    "    q = 0\n",
    "    for i in range(len(mask_paths)):\n",
    "        mask_paths_dic[str(p)+'_'+str(q)] = mask_paths[i]\n",
    "        if q==6:\n",
    "            q=0\n",
    "            p=p+1\n",
    "        else:\n",
    "            q=q+1\n",
    "        \n",
    "    img_mask_list = []\n",
    "    #print(img_paths_dic)\n",
    "    \n",
    "    for key in img_paths_dic:\n",
    "        img_mask_list.append((img_paths_dic[key], mask_paths_dic[key]))\n",
    "        \n",
    "    train_img_mask_paths = img_mask_list[:int(len_data*train_size)] \n",
    "    val_img_mask_paths = img_mask_list[int(len_data*train_size):]\n",
    "    return train_img_mask_paths, val_img_mask_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding(data, block_size):\n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[0]/block_size[0])\n",
    "    #Calculate required padding size \n",
    "    pad_val_c = (block_size[0] * ceil_val) - data.shape[0]\n",
    "    \n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[1]/block_size[1])\n",
    "    #Calculate required padding size\n",
    "    pad_val_h = (block_size[1] * ceil_val) - data.shape[1]\n",
    "    \n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[2]/block_size[2])\n",
    "    # Calculate required padding size\n",
    "    pad_val_w = (block_size[2] * ceil_val) - data.shape[2]\n",
    "    \n",
    "    # Constant padding\n",
    "    #data = data.numpy()\n",
    "    data = np.pad(data, ((0,pad_val_c),(0,pad_val_h),(0,pad_val_w)), 'constant')\n",
    "    #data = np.array(data, dtype=np.int16)\n",
    "    \n",
    "    #changed dtype to float\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_data_blocks(data, block_size ):\n",
    "    x = torch.from_numpy(data)\n",
    "    # Add a dimension at 0th position\n",
    "    x = x.unsqueeze(0)\n",
    "    # Kernel Size\n",
    "    kc, kh, kw = block_size[0], block_size[1], block_size[2]\n",
    "    # stride\n",
    "    dc, dh, dw = block_size[0], block_size[1], block_size[2]\n",
    "    patches = x.unfold(1, kc, dc).unfold(2, kh, dh).unfold(3, kw, dw)\n",
    "    unfold_shape = patches.size()\n",
    "    patches = patches.contiguous().view(patches.size(0), -1, kc, kh, kw)\n",
    "    #Return Patches and Unfold Shape\n",
    "    return patches, unfold_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesize = (48,100,100)\n",
    "def preprocess_image(image_mask_paths):\n",
    "    img_mask_list = []\n",
    "\n",
    "    for i in tqdm(range(len(image_mask_paths))):\n",
    "        vol = nib.load(image_mask_paths[i][0])\n",
    "        m = nib.load(image_mask_paths[i][1])\n",
    "        img = np.array(vol.get_data(), np.float32)\n",
    "        #img_padded = np.pad(img, ((0,2),(0,2),(0,2)), 'constant')\n",
    "        mask = np.array(m.get_data(),np.float32)\n",
    "        #mask_padded = mask\n",
    "        img = nn.functional.interpolate(torch.from_numpy(img).unsqueeze(0).unsqueeze(0), size=imagesize, mode='trilinear')\n",
    "        img = img / torch.max(img)\n",
    "        mask = nn.functional.interpolate(torch.from_numpy(mask).unsqueeze(0).unsqueeze(0), size=imagesize, mode='trilinear')\n",
    "        mask = mask / torch.max(mask)\n",
    "        mask[mask > 0.5] = 1\n",
    "        mask[mask <= 0.5] = 0\n",
    "        img_mask_list.append((img.squeeze().squeeze().numpy(),mask.squeeze().squeeze().numpy()))\n",
    "    return img_mask_list\n",
    "    '''#mask_padded = zero_padding(mask, block_size)\n",
    "\n",
    "        # Generate data blocks of block_size\n",
    "        img_blocks, unfold_shape_img = get_data_blocks(data = img_padded, block_size = block_size)\n",
    "        mask_blocks, unfold_shape_mask = get_data_blocks(data = mask_padded, block_size = block_size)\n",
    "\n",
    "        img_array = img_blocks.numpy()\n",
    "        mask_array = mask_blocks.numpy()\n",
    "        per_img = []\n",
    "        per_mask = []\n",
    "        if i<1:\n",
    "            for j in range(len(img_array[0])):\n",
    "                #if np.sum(mask_array[0][j])>0:\n",
    "                img_mask_list.append((img_array[0][j], mask_array[0][j]))\n",
    "                #print(img_array[0][i].shape)\n",
    "        else:\n",
    "            for j in range(len(img_array[0])):\n",
    "                #if np.sum(mask_array[0][j])>0:\n",
    "                img_mask_list.append((img_array[0][j], mask_array[0][j]))\n",
    "\n",
    "    return img_mask_list '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total len: 15\n",
      "[('data/Pre-processed training dataset\\\\01016SACH\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\01016SACH\\\\Consensus.nii.gz'), ('data/Pre-processed training dataset\\\\01038PAGU\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\01038PAGU\\\\Consensus.nii.gz'), ('data/Pre-processed training dataset\\\\01039VITE\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\01039VITE\\\\Consensus.nii.gz'), ('data/Pre-processed training dataset\\\\01040VANE\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\01040VANE\\\\Consensus.nii.gz'), ('data/Pre-processed training dataset\\\\01042GULE\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\01042GULE\\\\Consensus.nii.gz'), ('data/Pre-processed training dataset\\\\07001MOEL\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\07001MOEL\\\\Consensus.nii.gz'), ('data/Pre-processed training dataset\\\\07003SATH\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\07003SATH\\\\Consensus.nii.gz'), ('data/Pre-processed training dataset\\\\07010NABO\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\07010NABO\\\\Consensus.nii.gz'), ('data/Pre-processed training dataset\\\\07040DORE\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\07040DORE\\\\Consensus.nii.gz')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.28s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "train_img_mask_paths, val_img_mask_paths = split_train_val(image_paths, mask_paths, 0.6)\n",
    "\n",
    "print(train_img_mask_paths)\n",
    "#Training:\n",
    "train_img_masks = preprocess_image(train_img_mask_paths)\n",
    "\n",
    "#Validation:\n",
    "val_img_masks = preprocess_image(val_img_mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(train_img_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Convert ndarrays in sample to Tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['img'], sample['label']\n",
    "        image = image[None,:,:]\n",
    "        label = label[None,:,:]\n",
    "#         image = image.numpy()\n",
    "#         label = label.numpy()\n",
    "        return {'img': torch.from_numpy(image.copy()).type(torch.FloatTensor),\n",
    "                'label': torch.from_numpy(label.copy()).type(torch.FloatTensor)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_masks, transforms=None):\n",
    "\n",
    "        self.image_masks = image_masks\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):  # return count of sample we have\n",
    "\n",
    "        return len(self.image_masks)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = self.image_masks[index][0] # H, W, C\n",
    "        mask = self.image_masks[index][1]\n",
    "\n",
    "#         image = np.transpose(image, axes=[2, 0, 1]) # C, H, W\n",
    "\n",
    "        sample = {'img': image, 'label': mask}\n",
    "\n",
    "        if transforms:\n",
    "            sample = self.transforms(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "train_dataset = CustomDataset(train_img_masks, transforms=transforms.Compose([ToTensor()]))\n",
    "val_dataset = CustomDataset(val_img_masks, transforms=transforms.Compose([ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define dice coefficient \n",
    "class DiceCoeff(Function):\n",
    "    \"\"\"Dice coeff for one pair of input image and target image\"\"\"\n",
    "    def forward(self, prediction, target):\n",
    "        self.save_for_backward(prediction, target)\n",
    "        eps = 0.0001 # in case union = 0\n",
    "        # Calculate intersection and union. \n",
    "        # You can convert the input image into a vector with input.contiguous().view(-1)\n",
    "        # Then use torch.dot(A, B) to calculate the intersection.\n",
    "        A = prediction.contiguous().view(-1)\n",
    "        B = target.contiguous().view(-1)\n",
    "        inter = torch.dot(A.float(),B.float())\n",
    "        #print(\"inter\", inter)\n",
    "        union = torch.sum(A.float()) + torch.sum(B.float()) - inter + eps\n",
    "        #print(\"union\", union)\n",
    "        # Calculate DICE \n",
    "        d = inter / union\n",
    "        #print(\"d\", d)\n",
    "        return d\n",
    "\n",
    "# Calculate dice coefficients for batches\n",
    "def dice_coeff(prediction, target):\n",
    "    \"\"\"Dice coeff for batches\"\"\"\n",
    "    s = torch.FloatTensor(1).zero_()\n",
    "    \n",
    "    # For each pair of input and target, call DiceCoeff().forward(prediction, target) to calculate dice coefficient\n",
    "    # Then average\n",
    "    for i, (a,b) in enumerate(zip(prediction, target)):\n",
    "        s += DiceCoeff().forward(a,b)\n",
    "    s = s / (i + 1)\n",
    "    return s\n",
    "\n",
    "def dice_loss(prediction, target):\n",
    "    eps = 0.0001 # in case union = 0\n",
    "    A = prediction\n",
    "    B = target\n",
    "    inter = torch.dot(A.float(),B.float())\n",
    "    union = torch.sum(A.float()) + torch.sum(B.float()) - inter + eps\n",
    "    d = inter / union\n",
    "    #print(\"d\", d)\n",
    "    return 1-d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, dataset):\n",
    "    # set net mode to evaluation\n",
    "    net.eval()\n",
    "    tot = 0\n",
    "    print(\"val dataset length:\", len(dataset))\n",
    "    for i, b in enumerate(dataset):\n",
    "        img = b['img'].to(device)\n",
    "        B = img.shape[0]\n",
    "        true_mask = b['label'].to(device)\n",
    "\n",
    "        # Feed the image to the network to get predicted mask\n",
    "        mask_pred = net(img.float())\n",
    "\n",
    "        # For all pixels in predicted mask, set them to 1 if larger than 0.5. Otherwise set them to 0\n",
    "        #mask_pred[mask_pred > 0.5] = 1\n",
    "        #mask_pred[mask_pred <= 0.5] = 0\n",
    "        #print(\"maskpred\", type(mask_pred), mask_pred.shape)\n",
    "        #print(\"true\", type(true_mask), true_mask.shape)\n",
    "        # calculate dice_coeff()\n",
    "        # note that you should add all the dice_coeff in validation/testing dataset together\n",
    "        # call dice_coeff() here\n",
    "        #masks_probs_flat = mask_pred.flatten()\n",
    "        #true_masks_flat = true_mask.flatten()\n",
    "        \n",
    "        #tot += dice_coeff(true_masks_flat,masks_probs_flat)\n",
    "        tot += dice_coeff(true_mask,mask_pred)\n",
    "        # Return average dice_coeff()\n",
    "    return tot / (i + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/300.\n",
      "0.0000 --- loss: 0.994170\n",
      "Epoch finished ! Loss: 0.9962607502937317\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0026], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 2/300.\n",
      "0.0000 --- loss: 0.985907\n",
      "Epoch finished ! Loss: 0.9920559167861939\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0050], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 3/300.\n",
      "0.0000 --- loss: 0.965753\n",
      "Epoch finished ! Loss: 0.9823922276496887\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0016], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 4/300.\n",
      "0.0000 --- loss: 0.921669\n",
      "Epoch finished ! Loss: 0.9753695130348206\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([4.6708e-05], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 5/300.\n",
      "0.0000 --- loss: 0.923574\n",
      "Epoch finished ! Loss: 0.9740333914756775\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0073], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 6/300.\n",
      "0.0000 --- loss: 0.861983\n",
      "Epoch finished ! Loss: 0.9552001714706421\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0169], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 7/300.\n",
      "0.0000 --- loss: 0.887655\n",
      "Epoch finished ! Loss: 0.959473443031311\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([1.7976e-05], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 8/300.\n",
      "0.0000 --- loss: 0.999996\n",
      "Epoch finished ! Loss: 0.9999978899955749\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([3.1363e-09], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 9/300.\n",
      "0.0000 --- loss: 0.999998\n",
      "Epoch finished ! Loss: 0.9999979615211487\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([2.2460e-09], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 10/300.\n",
      "0.0000 --- loss: 0.999989\n",
      "Epoch finished ! Loss: 0.9999621868133545\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([1.2019e-09], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 11/300.\n",
      "0.0000 --- loss: 0.996179\n",
      "Epoch finished ! Loss: 0.9992030024528503\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0182], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 12/300.\n",
      "0.0000 --- loss: 0.999980\n",
      "Epoch finished ! Loss: 0.9985871315002441\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0123], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 13/300.\n",
      "0.0000 --- loss: 0.902207\n",
      "Epoch finished ! Loss: 0.973747169971466\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0129], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 14/300.\n",
      "0.0000 --- loss: 0.872350\n",
      "Epoch finished ! Loss: 0.9639990568161011\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0140], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 15/300.\n",
      "0.0000 --- loss: 0.941563\n",
      "Epoch finished ! Loss: 0.9745554089546203\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0367], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 16/300.\n",
      "0.0000 --- loss: 0.950772\n",
      "Epoch finished ! Loss: 0.9774440169334412\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0075], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 17/300.\n",
      "0.0000 --- loss: 0.952517\n",
      "Epoch finished ! Loss: 0.9780681371688843\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([3.7278e-07], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 18/300.\n",
      "0.0000 --- loss: 0.943006\n",
      "Epoch finished ! Loss: 0.9791832566261292\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0276], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 19/300.\n",
      "0.0000 --- loss: 0.953240\n",
      "Epoch finished ! Loss: 0.980473268032074\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([1.1100e-05], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 20/300.\n",
      "0.0000 --- loss: 0.963655\n",
      "Epoch finished ! Loss: 0.9799672126770019\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0119], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 21/300.\n",
      "0.0000 --- loss: 0.956185\n",
      "Epoch finished ! Loss: 0.9794028162956238\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0351], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 22/300.\n",
      "0.0000 --- loss: 0.930899\n",
      "Epoch finished ! Loss: 0.974900484085083\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0061], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 23/300.\n",
      "0.0000 --- loss: 0.946303\n",
      "Epoch finished ! Loss: 0.981156849861145\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 24/300.\n",
      "0.0000 --- loss: 0.974812\n",
      "Epoch finished ! Loss: 0.9800955295562744\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0151], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 25/300.\n",
      "0.0000 --- loss: 0.967500\n",
      "Epoch finished ! Loss: 0.9831480145454407\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0177], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 26/300.\n",
      "0.0000 --- loss: 0.997732\n",
      "Epoch finished ! Loss: 0.9897979617118835\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0040], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 27/300.\n",
      "0.0000 --- loss: 0.952668\n",
      "Epoch finished ! Loss: 0.9835620522499084\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0118], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 28/300.\n",
      "0.0000 --- loss: 0.935961\n",
      "Epoch finished ! Loss: 0.9802340388298034\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([1.3290e-07], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 29/300.\n",
      "0.0000 --- loss: 0.990923\n",
      "Epoch finished ! Loss: 0.9844330787658692\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0086], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 30/300.\n",
      "0.0000 --- loss: 0.939854\n",
      "Epoch finished ! Loss: 0.9755762457847595\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0385], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 31/300.\n",
      "0.0000 --- loss: 0.933018\n",
      "Epoch finished ! Loss: 0.9756512403488159\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0091], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 32/300.\n",
      "0.0000 --- loss: 0.953339\n",
      "Epoch finished ! Loss: 0.9781264185905456\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0298], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 33/300.\n",
      "0.0000 --- loss: 0.950022\n",
      "Epoch finished ! Loss: 0.9788818717002868\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 34/300.\n",
      "0.0000 --- loss: 0.955364\n",
      "Epoch finished ! Loss: 0.9779201865196228\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0182], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 35/300.\n",
      "0.0000 --- loss: 0.950054\n",
      "Epoch finished ! Loss: 0.9773113131523132\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0368], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 36/300.\n",
      "0.0000 --- loss: 0.941797\n",
      "Epoch finished ! Loss: 0.9794209957122803\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([7.1654e-05], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 37/300.\n",
      "0.0000 --- loss: 0.827299\n",
      "Epoch finished ! Loss: 0.9653078794479371\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([4.3561e-05], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 38/300.\n",
      "0.0000 --- loss: 0.978055\n",
      "Epoch finished ! Loss: 0.9817392110824585\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0048], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 39/300.\n",
      "0.0000 --- loss: 0.946303\n",
      "Epoch finished ! Loss: 0.9757829666137695\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0115], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 40/300.\n",
      "0.0000 --- loss: 0.949173\n",
      "Epoch finished ! Loss: 0.9767366170883178\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0235], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 41/300.\n",
      "0.0000 --- loss: 0.934845\n",
      "Epoch finished ! Loss: 0.975735855102539\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0088], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 42/300.\n",
      "0.0000 --- loss: 0.896248\n",
      "Epoch finished ! Loss: 0.9676815152168274\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0149], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 43/300.\n",
      "0.0000 --- loss: 0.918733\n",
      "Epoch finished ! Loss: 0.9736179232597351\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 44/300.\n",
      "0.0000 --- loss: 0.899530\n",
      "Epoch finished ! Loss: 0.9647581338882446\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0042], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 45/300.\n",
      "0.0000 --- loss: 0.951593\n",
      "Epoch finished ! Loss: 0.9773023247718811\n",
      "val dataset length: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Coeff: tensor([0.0103], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 46/300.\n",
      "0.0000 --- loss: 0.952923\n",
      "Epoch finished ! Loss: 0.9776294827461243\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 47/300.\n",
      "0.0000 --- loss: 0.943010\n",
      "Epoch finished ! Loss: 0.9886018753051757\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([2.6429e-06], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 48/300.\n",
      "0.0000 --- loss: 1.000000\n",
      "Epoch finished ! Loss: 0.9999984979629517\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([4.9864e-05], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 49/300.\n",
      "0.0000 --- loss: 0.999981\n",
      "Epoch finished ! Loss: 0.9999842762947082\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 50/300.\n",
      "0.0000 --- loss: 0.999994\n",
      "Epoch finished ! Loss: 0.9999731779098511\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([5.9978e-05], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 51/300.\n",
      "0.0000 --- loss: 0.999637\n",
      "Epoch finished ! Loss: 0.9974834442138671\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0037], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 52/300.\n",
      "0.0000 --- loss: 0.953888\n",
      "Epoch finished ! Loss: 0.9777621626853943\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0096], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 53/300.\n",
      "0.0000 --- loss: 0.945827\n",
      "Epoch finished ! Loss: 0.9746337890625\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0216], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 54/300.\n",
      "0.0000 --- loss: 0.951871\n",
      "Epoch finished ! Loss: 0.9759863138198852\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0209], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 55/300.\n",
      "0.0000 --- loss: 0.932837\n",
      "Epoch finished ! Loss: 0.9719218611717224\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0017], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 56/300.\n",
      "0.0000 --- loss: 0.936713\n",
      "Epoch finished ! Loss: 0.9752235531806945\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 57/300.\n",
      "0.0000 --- loss: 0.964663\n",
      "Epoch finished ! Loss: 0.9823877573013305\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0105], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 58/300.\n",
      "0.0000 --- loss: 0.910671\n",
      "Epoch finished ! Loss: 0.9709932208061218\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0218], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 59/300.\n",
      "0.0000 --- loss: 0.924789\n",
      "Epoch finished ! Loss: 0.9691924691200257\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0142], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 60/300.\n",
      "0.0000 --- loss: 0.950263\n",
      "Epoch finished ! Loss: 0.977359938621521\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0225], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 61/300.\n",
      "0.0000 --- loss: 0.947482\n",
      "Epoch finished ! Loss: 0.9764332294464111\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0313], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 62/300.\n",
      "0.0000 --- loss: 0.946987\n",
      "Epoch finished ! Loss: 0.9759262561798095\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0291], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 63/300.\n",
      "0.0000 --- loss: 0.945936\n",
      "Epoch finished ! Loss: 0.9753551006317138\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0266], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 64/300.\n",
      "0.0000 --- loss: 0.944277\n",
      "Epoch finished ! Loss: 0.9742427587509155\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0233], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 65/300.\n",
      "0.0000 --- loss: 0.933731\n",
      "Epoch finished ! Loss: 0.968790602684021\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0191], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 66/300.\n",
      "0.0000 --- loss: 0.928289\n",
      "Epoch finished ! Loss: 0.9624509572982788\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0175], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 67/300.\n",
      "0.0000 --- loss: 0.930446\n",
      "Epoch finished ! Loss: 0.9659132957458496\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0142], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 68/300.\n",
      "0.0000 --- loss: 0.924821\n",
      "Epoch finished ! Loss: 0.9643458843231201\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0053], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 69/300.\n",
      "0.0000 --- loss: 0.900094\n",
      "Epoch finished ! Loss: 0.9574789047241211\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 70/300.\n",
      "0.0000 --- loss: 0.977630\n",
      "Epoch finished ! Loss: 0.97279851436615\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0060], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 71/300.\n",
      "0.0000 --- loss: 0.979987\n",
      "Epoch finished ! Loss: 0.9730857014656067\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0146], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 72/300.\n",
      "0.0000 --- loss: 0.903042\n",
      "Epoch finished ! Loss: 0.9567777633666992\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0457], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 73/300.\n",
      "0.0000 --- loss: 0.876462\n",
      "Epoch finished ! Loss: 0.9409708738327026\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0124], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 74/300.\n",
      "0.0000 --- loss: 0.837962\n",
      "Epoch finished ! Loss: 0.9322755217552186\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0284], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 75/300.\n",
      "0.0000 --- loss: 0.883327\n",
      "Epoch finished ! Loss: 0.9376663327217102\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0381], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 76/300.\n",
      "0.0000 --- loss: 0.815099\n",
      "Epoch finished ! Loss: 0.9158190011978149\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0440], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 77/300.\n",
      "0.0000 --- loss: 0.777107\n",
      "Epoch finished ! Loss: 0.9006972551345825\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 78/300.\n",
      "0.0000 --- loss: 0.870480\n",
      "Epoch finished ! Loss: 0.91357980966568\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0091], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 79/300.\n",
      "0.0000 --- loss: 0.800403\n",
      "Epoch finished ! Loss: 0.8921805858612061\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 80/300.\n",
      "0.0000 --- loss: 0.847164\n",
      "Epoch finished ! Loss: 0.8870736956596375\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 81/300.\n",
      "0.0000 --- loss: 0.874156\n",
      "Epoch finished ! Loss: 0.8729969024658203\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([4.5005e-05], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 82/300.\n",
      "0.0000 --- loss: 0.985967\n",
      "Epoch finished ! Loss: 0.9132996559143066\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0036], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 83/300.\n",
      "0.0000 --- loss: 0.864009\n",
      "Epoch finished ! Loss: 0.8656932950019837\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0694], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 84/300.\n",
      "0.0000 --- loss: 0.816946\n",
      "Epoch finished ! Loss: 0.8499630451202392\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 85/300.\n",
      "0.0000 --- loss: 0.836852\n",
      "Epoch finished ! Loss: 0.8436110734939575\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0597], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 86/300.\n",
      "0.0000 --- loss: 0.766983\n",
      "Epoch finished ! Loss: 0.7821173429489136\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1287], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 87/300.\n",
      "0.0000 --- loss: 0.785375\n",
      "Epoch finished ! Loss: 0.7904809355735779\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0019], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 88/300.\n",
      "0.0000 --- loss: 0.752654\n",
      "Epoch finished ! Loss: 0.7655461311340332\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([1.4489e-07], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 89/300.\n",
      "0.0000 --- loss: 0.777546\n",
      "Epoch finished ! Loss: 0.7405452132225037\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1365], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 90/300.\n",
      "0.0000 --- loss: 0.729542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch finished ! Loss: 0.753603994846344\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([6.3136e-06], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 91/300.\n",
      "0.0000 --- loss: 0.718643\n",
      "Epoch finished ! Loss: 0.7292908787727356\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([1.4756e-07], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 92/300.\n",
      "0.0000 --- loss: 0.679981\n",
      "Epoch finished ! Loss: 0.7080288171768189\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0845], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 93/300.\n",
      "0.0000 --- loss: 0.657021\n",
      "Epoch finished ! Loss: 0.6848868250846862\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0044], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 94/300.\n",
      "0.0000 --- loss: 0.718982\n",
      "Epoch finished ! Loss: 0.6906430840492248\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2118], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 95/300.\n",
      "0.0000 --- loss: 0.692794\n",
      "Epoch finished ! Loss: 0.6724892854690552\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0544], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 96/300.\n",
      "0.0000 --- loss: 0.631045\n",
      "Epoch finished ! Loss: 0.6598696112632751\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1896], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 97/300.\n",
      "0.0000 --- loss: 0.618983\n",
      "Epoch finished ! Loss: 0.7090242862701416\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1158], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 98/300.\n",
      "0.0000 --- loss: 0.631788\n",
      "Epoch finished ! Loss: 0.6426366567611694\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1680], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 99/300.\n",
      "0.0000 --- loss: 0.621453\n",
      "Epoch finished ! Loss: 0.6660902619361877\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1749], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 100/300.\n",
      "0.0000 --- loss: 0.623518\n",
      "Epoch finished ! Loss: 0.673772132396698\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2288], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 101/300.\n",
      "0.0000 --- loss: 0.576288\n",
      "Epoch finished ! Loss: 0.6419631361961364\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2361], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 102/300.\n",
      "0.0000 --- loss: 0.585342\n",
      "Epoch finished ! Loss: 0.6227429747581482\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2197], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 103/300.\n",
      "0.0000 --- loss: 0.562971\n",
      "Epoch finished ! Loss: 0.6193838477134704\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2429], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 104/300.\n",
      "0.0000 --- loss: 0.582296\n",
      "Epoch finished ! Loss: 0.6161090016365052\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1667], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 105/300.\n",
      "0.0000 --- loss: 0.588948\n",
      "Epoch finished ! Loss: 0.6292261600494384\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0127], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 106/300.\n",
      "0.0000 --- loss: 0.722524\n",
      "Epoch finished ! Loss: 0.655733072757721\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0528], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 107/300.\n",
      "0.0000 --- loss: 0.593560\n",
      "Epoch finished ! Loss: 0.6156208992004395\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2080], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 108/300.\n",
      "0.0000 --- loss: 0.540232\n",
      "Epoch finished ! Loss: 0.6265801429748535\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1648], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 109/300.\n",
      "0.0000 --- loss: 0.563336\n",
      "Epoch finished ! Loss: 0.6432503461837769\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1606], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 110/300.\n",
      "0.0000 --- loss: 0.747001\n",
      "Epoch finished ! Loss: 0.6587417006492615\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1698], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 111/300.\n",
      "0.0000 --- loss: 0.594798\n",
      "Epoch finished ! Loss: 0.6109564423561096\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2048], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 112/300.\n",
      "0.0000 --- loss: 0.567495\n",
      "Epoch finished ! Loss: 0.6068140983581543\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1643], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 113/300.\n",
      "0.0000 --- loss: 0.659390\n",
      "Epoch finished ! Loss: 0.6146488785743713\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0973], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 114/300.\n",
      "0.0000 --- loss: 0.539287\n",
      "Epoch finished ! Loss: 0.6128473877906799\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0284], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 115/300.\n",
      "0.0000 --- loss: 0.547523\n",
      "Epoch finished ! Loss: 0.5831190824508667\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2679], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 116/300.\n",
      "0.0000 --- loss: 0.538150\n",
      "Epoch finished ! Loss: 0.5960448384284973\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2627], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 117/300.\n",
      "0.0000 --- loss: 0.569785\n",
      "Epoch finished ! Loss: 0.5822762370109558\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1331], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 118/300.\n",
      "0.0000 --- loss: 0.607421\n",
      "Epoch finished ! Loss: 0.5880795001983643\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2593], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 119/300.\n",
      "0.0000 --- loss: 0.557395\n",
      "Epoch finished ! Loss: 0.5617706775665283\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2701], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 120/300.\n",
      "0.0000 --- loss: 0.551898\n",
      "Epoch finished ! Loss: 0.5431758403778076\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2512], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 121/300.\n",
      "0.0000 --- loss: 0.532337\n",
      "Epoch finished ! Loss: 0.5382995367050171\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2125], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 122/300.\n",
      "0.0000 --- loss: 0.502079\n",
      "Epoch finished ! Loss: 0.5309323787689209\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2682], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 123/300.\n",
      "0.0000 --- loss: 0.494507\n",
      "Epoch finished ! Loss: 0.5552939653396607\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0668], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 124/300.\n",
      "0.0000 --- loss: 0.596077\n",
      "Epoch finished ! Loss: 0.5658602476119995\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1820], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 125/300.\n",
      "0.0000 --- loss: 0.536214\n",
      "Epoch finished ! Loss: 0.5379123449325561\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2715], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 126/300.\n",
      "0.0000 --- loss: 0.537396\n",
      "Epoch finished ! Loss: 0.5381076693534851\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2929], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 127/300.\n",
      "0.0000 --- loss: 0.504606\n",
      "Epoch finished ! Loss: 0.5091588854789734\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2370], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 128/300.\n",
      "0.0000 --- loss: 0.498142\n",
      "Epoch finished ! Loss: 0.5072811603546142\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2822], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 129/300.\n",
      "0.0000 --- loss: 0.496657\n",
      "Epoch finished ! Loss: 0.5202982187271118\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2765], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 130/300.\n",
      "0.0000 --- loss: 0.475292\n",
      "Epoch finished ! Loss: 0.4960159778594971\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3140], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 131/300.\n",
      "0.0000 --- loss: 0.493070\n",
      "Epoch finished ! Loss: 0.5155438661575318\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2957], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 132/300.\n",
      "0.0000 --- loss: 0.465370\n",
      "Epoch finished ! Loss: 0.514167058467865\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2146], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 133/300.\n",
      "0.0000 --- loss: 0.472381\n",
      "Epoch finished ! Loss: 0.5277740478515625\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1436], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 134/300.\n",
      "0.0000 --- loss: 0.498318\n",
      "Epoch finished ! Loss: 0.529722023010254\n",
      "val dataset length: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Coeff: tensor([0.1809], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 135/300.\n",
      "0.0000 --- loss: 0.495988\n",
      "Epoch finished ! Loss: 0.4997503161430359\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2712], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 136/300.\n",
      "0.0000 --- loss: 0.465174\n",
      "Epoch finished ! Loss: 0.49606133699417115\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0877], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 137/300.\n",
      "0.0000 --- loss: 0.503291\n",
      "Epoch finished ! Loss: 0.5282011508941651\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3024], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 138/300.\n",
      "0.0000 --- loss: 0.526958\n",
      "Epoch finished ! Loss: 0.5205758213996887\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2281], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 139/300.\n",
      "0.0000 --- loss: 0.508537\n",
      "Epoch finished ! Loss: 0.5055544972419739\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0610], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 140/300.\n",
      "0.0000 --- loss: 0.536296\n",
      "Epoch finished ! Loss: 0.5040056943893433\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3015], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 141/300.\n",
      "0.0000 --- loss: 0.464955\n",
      "Epoch finished ! Loss: 0.4744487524032593\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2748], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 142/300.\n",
      "0.0000 --- loss: 0.456439\n",
      "Epoch finished ! Loss: 0.4900403141975403\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2727], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 143/300.\n",
      "0.0000 --- loss: 0.524642\n",
      "Epoch finished ! Loss: 0.5084707975387573\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2944], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 144/300.\n",
      "0.0000 --- loss: 0.512492\n",
      "Epoch finished ! Loss: 0.49565528631210326\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1589], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 145/300.\n",
      "0.0000 --- loss: 0.450424\n",
      "Epoch finished ! Loss: 0.4892559051513672\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1651], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 146/300.\n",
      "0.0000 --- loss: 0.481910\n",
      "Epoch finished ! Loss: 0.5425447344779968\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0717], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 147/300.\n",
      "0.0000 --- loss: 0.537384\n",
      "Epoch finished ! Loss: 0.5356159925460815\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2761], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 148/300.\n",
      "0.0000 --- loss: 0.555960\n",
      "Epoch finished ! Loss: 0.5454989671707153\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1587], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 149/300.\n",
      "0.0000 --- loss: 0.469310\n",
      "Epoch finished ! Loss: 0.47874161005020144\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3074], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 150/300.\n",
      "0.0000 --- loss: 0.467514\n",
      "Epoch finished ! Loss: 0.4762110710144043\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3122], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 151/300.\n",
      "0.0000 --- loss: 0.456063\n",
      "Epoch finished ! Loss: 0.47134881019592284\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0879], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 152/300.\n",
      "0.0000 --- loss: 0.631657\n",
      "Epoch finished ! Loss: 0.519913649559021\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1697], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 153/300.\n",
      "0.0000 --- loss: 0.463945\n",
      "Epoch finished ! Loss: 0.5055989384651184\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2570], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 154/300.\n",
      "0.0000 --- loss: 0.481726\n",
      "Epoch finished ! Loss: 0.5042143344879151\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0750], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 155/300.\n",
      "0.0000 --- loss: 0.504655\n",
      "Epoch finished ! Loss: 0.4921013832092285\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2836], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 156/300.\n",
      "0.0000 --- loss: 0.454932\n",
      "Epoch finished ! Loss: 0.5004636287689209\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3120], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 157/300.\n",
      "0.0000 --- loss: 0.487515\n",
      "Epoch finished ! Loss: 0.4984330892562866\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3042], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 158/300.\n",
      "0.0000 --- loss: 0.451257\n",
      "Epoch finished ! Loss: 0.484090781211853\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2438], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 159/300.\n",
      "0.0000 --- loss: 0.440424\n",
      "Epoch finished ! Loss: 0.467297101020813\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2994], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 160/300.\n",
      "0.0000 --- loss: 0.440023\n",
      "Epoch finished ! Loss: 0.4764531373977661\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3116], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 161/300.\n",
      "0.0000 --- loss: 0.486161\n",
      "Epoch finished ! Loss: 0.46319453716278075\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3140], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 162/300.\n",
      "0.0000 --- loss: 0.442899\n",
      "Epoch finished ! Loss: 0.4761216402053833\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2400], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 163/300.\n",
      "0.0000 --- loss: 0.437163\n",
      "Epoch finished ! Loss: 0.5071056842803955\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2109], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 164/300.\n",
      "0.0000 --- loss: 0.541209\n",
      "Epoch finished ! Loss: 0.5152264952659606\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2388], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 165/300.\n",
      "0.0000 --- loss: 0.480827\n",
      "Epoch finished ! Loss: 0.4746363043785095\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2843], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 166/300.\n",
      "0.0000 --- loss: 0.482868\n",
      "Epoch finished ! Loss: 0.46833033561706544\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1662], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 167/300.\n",
      "0.0000 --- loss: 0.456505\n",
      "Epoch finished ! Loss: 0.45400998592376707\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2321], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 168/300.\n",
      "0.0000 --- loss: 0.437241\n",
      "Epoch finished ! Loss: 0.4768245220184326\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2902], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 169/300.\n",
      "0.0000 --- loss: 0.441768\n",
      "Epoch finished ! Loss: 0.47974286079406736\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0903], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 170/300.\n",
      "0.0000 --- loss: 0.462353\n",
      "Epoch finished ! Loss: 0.47378246784210204\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3257], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 171/300.\n",
      "0.0000 --- loss: 0.457377\n",
      "Epoch finished ! Loss: 0.4761683702468872\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3203], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 172/300.\n",
      "0.0000 --- loss: 0.451660\n",
      "Epoch finished ! Loss: 0.47176969051361084\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3086], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 173/300.\n",
      "0.0000 --- loss: 0.428780\n",
      "Epoch finished ! Loss: 0.453261137008667\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1334], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 174/300.\n",
      "0.0000 --- loss: 0.473774\n",
      "Epoch finished ! Loss: 0.46728456020355225\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2462], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 175/300.\n",
      "0.0000 --- loss: 0.431907\n",
      "Epoch finished ! Loss: 0.43267462253570554\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3287], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 176/300.\n",
      "0.0000 --- loss: 0.430124\n",
      "Epoch finished ! Loss: 0.45912379026412964\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2745], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 177/300.\n",
      "0.0000 --- loss: 0.460004\n",
      "Epoch finished ! Loss: 0.43611334562301635\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2850], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 178/300.\n",
      "0.0000 --- loss: 0.442995\n",
      "Epoch finished ! Loss: 0.4224526882171631\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3257], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 179/300.\n",
      "0.0000 --- loss: 0.433998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch finished ! Loss: 0.4261134028434753\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3014], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 180/300.\n",
      "0.0000 --- loss: 0.421739\n",
      "Epoch finished ! Loss: 0.42999145984649656\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2975], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 181/300.\n",
      "0.0000 --- loss: 0.411842\n",
      "Epoch finished ! Loss: 0.4183465003967285\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3243], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 182/300.\n",
      "0.0000 --- loss: 0.467728\n",
      "Epoch finished ! Loss: 0.4489222764968872\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2346], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 183/300.\n",
      "0.0000 --- loss: 0.419703\n",
      "Epoch finished ! Loss: 0.4271994948387146\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2877], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 184/300.\n",
      "0.0000 --- loss: 0.420982\n",
      "Epoch finished ! Loss: 0.4605793356895447\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3332], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 185/300.\n",
      "0.0000 --- loss: 0.445570\n",
      "Epoch finished ! Loss: 0.43840197324752805\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1885], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 186/300.\n",
      "0.0000 --- loss: 0.420933\n",
      "Epoch finished ! Loss: 0.4276165008544922\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2791], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 187/300.\n",
      "0.0000 --- loss: 0.421782\n",
      "Epoch finished ! Loss: 0.42900063991546633\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3184], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 188/300.\n",
      "0.0000 --- loss: 0.429545\n",
      "Epoch finished ! Loss: 0.40894529819488523\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2854], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 189/300.\n",
      "0.0000 --- loss: 0.422730\n",
      "Epoch finished ! Loss: 0.4053466558456421\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3063], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 190/300.\n",
      "0.0000 --- loss: 0.408849\n",
      "Epoch finished ! Loss: 0.40643404722213744\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2644], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 191/300.\n",
      "0.0000 --- loss: 0.402431\n",
      "Epoch finished ! Loss: 0.4680125117301941\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2849], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 192/300.\n",
      "0.0000 --- loss: 0.489684\n",
      "Epoch finished ! Loss: 0.4526844620704651\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1865], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 193/300.\n",
      "0.0000 --- loss: 0.512586\n",
      "Epoch finished ! Loss: 0.5061314940452576\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1818], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 194/300.\n",
      "0.0000 --- loss: 0.825516\n",
      "Epoch finished ! Loss: 0.636006760597229\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1160], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 195/300.\n",
      "0.0000 --- loss: 0.520099\n",
      "Epoch finished ! Loss: 0.5928648233413696\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0533], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 196/300.\n",
      "0.0000 --- loss: 0.632323\n",
      "Epoch finished ! Loss: 0.5858155608177185\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2841], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 197/300.\n",
      "0.0000 --- loss: 0.517073\n",
      "Epoch finished ! Loss: 0.5197995901107788\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1848], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 198/300.\n",
      "0.0000 --- loss: 0.463542\n",
      "Epoch finished ! Loss: 0.4928072810173035\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2424], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 199/300.\n",
      "0.0000 --- loss: 0.492227\n",
      "Epoch finished ! Loss: 0.47851482629776\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1713], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 200/300.\n",
      "0.0000 --- loss: 0.448402\n",
      "Epoch finished ! Loss: 0.48176097869873047\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3257], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 201/300.\n",
      "0.0000 --- loss: 0.470419\n",
      "Epoch finished ! Loss: 0.4790415644645691\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0762], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 202/300.\n",
      "0.0000 --- loss: 0.594722\n",
      "Epoch finished ! Loss: 0.5436616659164428\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1651], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 203/300.\n",
      "0.0000 --- loss: 0.475994\n",
      "Epoch finished ! Loss: 0.4920122981071472\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3046], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 204/300.\n",
      "0.0000 --- loss: 0.447236\n",
      "Epoch finished ! Loss: 0.4479820251464844\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2293], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 205/300.\n",
      "0.0000 --- loss: 0.459165\n",
      "Epoch finished ! Loss: 0.45470318794250486\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3227], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 206/300.\n",
      "0.0000 --- loss: 0.482659\n",
      "Epoch finished ! Loss: 0.4659236669540405\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2259], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 207/300.\n",
      "0.0000 --- loss: 0.413682\n",
      "Epoch finished ! Loss: 0.4331615686416626\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2701], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 208/300.\n",
      "0.0000 --- loss: 0.429379\n",
      "Epoch finished ! Loss: 0.4869738817214966\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3175], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 209/300.\n",
      "0.0000 --- loss: 0.436415\n",
      "Epoch finished ! Loss: 0.4797650933265686\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.1871], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 210/300.\n",
      "0.0000 --- loss: 0.479906\n",
      "Epoch finished ! Loss: 0.4970131516456604\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.0020], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 211/300.\n",
      "0.0000 --- loss: 0.451152\n",
      "Epoch finished ! Loss: 0.4752562761306763\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2490], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 212/300.\n",
      "0.0000 --- loss: 0.434355\n",
      "Epoch finished ! Loss: 0.4419864773750305\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3177], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 213/300.\n",
      "0.0000 --- loss: 0.428027\n",
      "Epoch finished ! Loss: 0.47661898136138914\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2820], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 214/300.\n",
      "0.0000 --- loss: 0.427771\n",
      "Epoch finished ! Loss: 0.4579764842987061\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3022], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 215/300.\n",
      "0.0000 --- loss: 0.459210\n",
      "Epoch finished ! Loss: 0.43967639207839965\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3097], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 216/300.\n",
      "0.0000 --- loss: 0.472663\n",
      "Epoch finished ! Loss: 0.45779105424880984\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3098], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 217/300.\n",
      "0.0000 --- loss: 0.438244\n",
      "Epoch finished ! Loss: 0.4188984274864197\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2700], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 218/300.\n",
      "0.0000 --- loss: 0.407970\n",
      "Epoch finished ! Loss: 0.4174776315689087\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.2918], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 219/300.\n",
      "0.0000 --- loss: 0.406043\n",
      "Epoch finished ! Loss: 0.40014785528182983\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3301], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 220/300.\n",
      "0.0000 --- loss: 0.412482\n",
      "Epoch finished ! Loss: 0.40290944576263427\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3305], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 221/300.\n",
      "0.0000 --- loss: 0.412452\n",
      "Epoch finished ! Loss: 0.39768974781036376\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3111], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 222/300.\n",
      "0.0000 --- loss: 0.404255\n",
      "Epoch finished ! Loss: 0.3964751482009888\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3095], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 223/300.\n",
      "0.0000 --- loss: 0.403857\n",
      "Epoch finished ! Loss: 0.39379507303237915\n",
      "val dataset length: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dice Coeff: tensor([0.3217], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 224/300.\n",
      "0.0000 --- loss: 0.406643\n",
      "Epoch finished ! Loss: 0.3931360363960266\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3231], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 225/300.\n",
      "0.0000 --- loss: 0.407141\n",
      "Epoch finished ! Loss: 0.39187403917312624\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3169], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 226/300.\n",
      "0.0000 --- loss: 0.404762\n",
      "Epoch finished ! Loss: 0.39119973182678225\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3160], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 227/300.\n",
      "0.0000 --- loss: 0.404516\n",
      "Epoch finished ! Loss: 0.39014086723327634\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3180], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 228/300.\n",
      "0.0000 --- loss: 0.405623\n",
      "Epoch finished ! Loss: 0.389463746547699\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3157], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 229/300.\n",
      "0.0000 --- loss: 0.405288\n",
      "Epoch finished ! Loss: 0.3887882590293884\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3125], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 230/300.\n",
      "0.0000 --- loss: 0.404397\n",
      "Epoch finished ! Loss: 0.38810176849365235\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3129], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 231/300.\n",
      "0.0000 --- loss: 0.404573\n",
      "Epoch finished ! Loss: 0.3874454855918884\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3140], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 232/300.\n",
      "0.0000 --- loss: 0.404902\n",
      "Epoch finished ! Loss: 0.3869236946105957\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 233/300.\n",
      "0.0000 --- loss: 0.404480\n",
      "Epoch finished ! Loss: 0.3863998532295227\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3128], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 234/300.\n",
      "0.0000 --- loss: 0.404022\n",
      "Epoch finished ! Loss: 0.3858527779579163\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3130], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 235/300.\n",
      "0.0000 --- loss: 0.403907\n",
      "Epoch finished ! Loss: 0.3853390455245972\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3128], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 236/300.\n",
      "0.0000 --- loss: 0.403684\n",
      "Epoch finished ! Loss: 0.3848523020744324\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3122], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 237/300.\n",
      "0.0000 --- loss: 0.403254\n",
      "Epoch finished ! Loss: 0.3843607783317566\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3119], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 238/300.\n",
      "0.0000 --- loss: 0.402962\n",
      "Epoch finished ! Loss: 0.3838676452636719\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3122], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 239/300.\n",
      "0.0000 --- loss: 0.402820\n",
      "Epoch finished ! Loss: 0.383382773399353\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3122], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 240/300.\n",
      "0.0000 --- loss: 0.402613\n",
      "Epoch finished ! Loss: 0.3829107403755188\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3123], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 241/300.\n",
      "0.0000 --- loss: 0.402366\n",
      "Epoch finished ! Loss: 0.38243335485458374\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3127], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 242/300.\n",
      "0.0000 --- loss: 0.402190\n",
      "Epoch finished ! Loss: 0.3819652199745178\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3130], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 243/300.\n",
      "0.0000 --- loss: 0.401996\n",
      "Epoch finished ! Loss: 0.38150771856307986\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3131], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 244/300.\n",
      "0.0000 --- loss: 0.401726\n",
      "Epoch finished ! Loss: 0.38105239868164065\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3130], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 245/300.\n",
      "0.0000 --- loss: 0.401455\n",
      "Epoch finished ! Loss: 0.38059684038162234\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3131], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 246/300.\n",
      "0.0000 --- loss: 0.401198\n",
      "Epoch finished ! Loss: 0.38014969825744627\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3132], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 247/300.\n",
      "0.0000 --- loss: 0.400901\n",
      "Epoch finished ! Loss: 0.37977529764175416\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3133], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 248/300.\n",
      "0.0000 --- loss: 0.400854\n",
      "Epoch finished ! Loss: 0.37973088026046753\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3133], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 249/300.\n",
      "0.0000 --- loss: 0.400791\n",
      "Epoch finished ! Loss: 0.37968584299087527\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3133], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 250/300.\n",
      "0.0000 --- loss: 0.400727\n",
      "Epoch finished ! Loss: 0.37964091300964353\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3132], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 251/300.\n",
      "0.0000 --- loss: 0.400671\n",
      "Epoch finished ! Loss: 0.37959585189819334\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3132], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 252/300.\n",
      "0.0000 --- loss: 0.400626\n",
      "Epoch finished ! Loss: 0.37955063581466675\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3133], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 253/300.\n",
      "0.0000 --- loss: 0.400591\n",
      "Epoch finished ! Loss: 0.37950557470321655\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3133], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 254/300.\n",
      "0.0000 --- loss: 0.400563\n",
      "Epoch finished ! Loss: 0.3794604539871216\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3133], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 255/300.\n",
      "0.0000 --- loss: 0.400539\n",
      "Epoch finished ! Loss: 0.37941555976867675\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3133], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 256/300.\n",
      "0.0000 --- loss: 0.400514\n",
      "Epoch finished ! Loss: 0.3793706655502319\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 257/300.\n",
      "0.0000 --- loss: 0.400489\n",
      "Epoch finished ! Loss: 0.37932602167129514\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 258/300.\n",
      "0.0000 --- loss: 0.400465\n",
      "Epoch finished ! Loss: 0.3792811393737793\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 259/300.\n",
      "0.0000 --- loss: 0.400441\n",
      "Epoch finished ! Loss: 0.37923628091812134\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 260/300.\n",
      "0.0000 --- loss: 0.400415\n",
      "Epoch finished ! Loss: 0.37919182777404786\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 261/300.\n",
      "0.0000 --- loss: 0.400387\n",
      "Epoch finished ! Loss: 0.37914725542068484\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 262/300.\n",
      "0.0000 --- loss: 0.400356\n",
      "Epoch finished ! Loss: 0.3791025161743164\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 263/300.\n",
      "0.0000 --- loss: 0.400324\n",
      "Epoch finished ! Loss: 0.3790575504302979\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 264/300.\n",
      "0.0000 --- loss: 0.400293\n",
      "Epoch finished ! Loss: 0.3790125250816345\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 265/300.\n",
      "0.0000 --- loss: 0.400264\n",
      "Epoch finished ! Loss: 0.3789677143096924\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 266/300.\n",
      "0.0000 --- loss: 0.400235\n",
      "Epoch finished ! Loss: 0.37892282009124756\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 267/300.\n",
      "0.0000 --- loss: 0.400206\n",
      "Epoch finished ! Loss: 0.3788776993751526\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3135], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 268/300.\n",
      "0.0000 --- loss: 0.400177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch finished ! Loss: 0.3788322567939758\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3135], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 269/300.\n",
      "0.0000 --- loss: 0.400144\n",
      "Epoch finished ! Loss: 0.37878708839416503\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 270/300.\n",
      "0.0000 --- loss: 0.400108\n",
      "Epoch finished ! Loss: 0.37874149084091185\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 271/300.\n",
      "0.0000 --- loss: 0.400071\n",
      "Epoch finished ! Loss: 0.37869585752487184\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 272/300.\n",
      "0.0000 --- loss: 0.400035\n",
      "Epoch finished ! Loss: 0.3786499500274658\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 273/300.\n",
      "0.0000 --- loss: 0.400000\n",
      "Epoch finished ! Loss: 0.37860440015792846\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 274/300.\n",
      "0.0000 --- loss: 0.399967\n",
      "Epoch finished ! Loss: 0.37855818271636965\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 275/300.\n",
      "0.0000 --- loss: 0.399937\n",
      "Epoch finished ! Loss: 0.37851203680038453\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 276/300.\n",
      "0.0000 --- loss: 0.399908\n",
      "Epoch finished ! Loss: 0.37846626043319703\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 277/300.\n",
      "0.0000 --- loss: 0.399879\n",
      "Epoch finished ! Loss: 0.3784202694892883\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 278/300.\n",
      "0.0000 --- loss: 0.399850\n",
      "Epoch finished ! Loss: 0.37838191986083985\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 279/300.\n",
      "0.0000 --- loss: 0.399847\n",
      "Epoch finished ! Loss: 0.37837733030319215\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 280/300.\n",
      "0.0000 --- loss: 0.399843\n",
      "Epoch finished ! Loss: 0.37837264537811277\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 281/300.\n",
      "0.0000 --- loss: 0.399839\n",
      "Epoch finished ! Loss: 0.3783680319786072\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 282/300.\n",
      "0.0000 --- loss: 0.399836\n",
      "Epoch finished ! Loss: 0.37836341857910155\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 283/300.\n",
      "0.0000 --- loss: 0.399832\n",
      "Epoch finished ! Loss: 0.37835872173309326\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 284/300.\n",
      "0.0000 --- loss: 0.399828\n",
      "Epoch finished ! Loss: 0.37835402488708497\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 285/300.\n",
      "0.0000 --- loss: 0.399824\n",
      "Epoch finished ! Loss: 0.3783493280410767\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 286/300.\n",
      "0.0000 --- loss: 0.399821\n",
      "Epoch finished ! Loss: 0.3783446431159973\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 287/300.\n",
      "0.0000 --- loss: 0.399817\n",
      "Epoch finished ! Loss: 0.378339958190918\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 288/300.\n",
      "0.0000 --- loss: 0.399813\n",
      "Epoch finished ! Loss: 0.3783352494239807\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 289/300.\n",
      "0.0000 --- loss: 0.399810\n",
      "Epoch finished ! Loss: 0.3783305287361145\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 290/300.\n",
      "0.0000 --- loss: 0.399806\n",
      "Epoch finished ! Loss: 0.3783257961273193\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 291/300.\n",
      "0.0000 --- loss: 0.399803\n",
      "Epoch finished ! Loss: 0.37832099199295044\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 292/300.\n",
      "0.0000 --- loss: 0.399799\n",
      "Epoch finished ! Loss: 0.3783162832260132\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 293/300.\n",
      "0.0000 --- loss: 0.399795\n",
      "Epoch finished ! Loss: 0.37831151485443115\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 294/300.\n",
      "0.0000 --- loss: 0.399792\n",
      "Epoch finished ! Loss: 0.3783066630363464\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 295/300.\n",
      "0.0000 --- loss: 0.399789\n",
      "Epoch finished ! Loss: 0.37830188274383547\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 296/300.\n",
      "0.0000 --- loss: 0.399785\n",
      "Epoch finished ! Loss: 0.37829703092575073\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 297/300.\n",
      "0.0000 --- loss: 0.399782\n",
      "Epoch finished ! Loss: 0.3782922148704529\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 298/300.\n",
      "0.0000 --- loss: 0.399778\n",
      "Epoch finished ! Loss: 0.3782873272895813\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 299/300.\n",
      "0.0000 --- loss: 0.399775\n",
      "Epoch finished ! Loss: 0.3782825946807861\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n",
      "Starting epoch 300/300.\n",
      "0.0000 --- loss: 0.399772\n",
      "Epoch finished ! Loss: 0.37827765941619873\n",
      "val dataset length: 3\n",
      "Validation Dice Coeff: tensor([0.3134], grad_fn=<DivBackward0>)\n",
      "lr 0.1\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "epochs = 300 # e.g. 10, or more until dice converge\n",
    "batch_size = 2 # e.g. 16\n",
    "lr = 0.1      # e.g. 0.01\n",
    "N_train = len(train_img_masks)\n",
    "model_save_path = 'model/'  # directory to same the model after each epoch.\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),lr = lr, weight_decay=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=30)\n",
    "criterion = nn.BCELoss()\n",
    "net.to(device)\n",
    "# Start training\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}/{}.'.format(epoch + 1, epochs))\n",
    "    net.train()\n",
    "    \n",
    "    # Reload images and masks for training and validation and perform random shuffling at the begining of each epoch\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    for i, b in enumerate(train_loader):\n",
    "        # Get images and masks from each batch\n",
    "\n",
    "        imgs = b['img'].to(device)\n",
    "        true_masks = b['label'].to(device)\n",
    "        #print('True mask shape: ',true_masks.shape, type(true_masks))\n",
    "        #print('images shape:', imgs.shape, type(imgs))\n",
    "        # Feed your images into the network\n",
    "        masks_pred = net.forward(imgs.float())\n",
    "        #print('Predicted mask shape: ',masks_pred.shape)\n",
    "        #masks_pred = nn.functional.interpolate(masks_pred, size=true_masks.shape, mode='bilinear')\n",
    "        # Flatten the predicted masks and true masks. For example, A_flat = A.view(-1)\n",
    "        #masks_probs_flat = masks_pred.view(-1)\n",
    "        #true_masks_flat = true_masks.view(-1)\n",
    "        #print('true_masks: ',true_masks.shape)\n",
    "        #print('masks_pred: ',masks_pred.shape)\n",
    "        masks_probs = masks_pred\n",
    "        \n",
    "        #masks_probs_flat = np.transpose(masks_probs_flat, axes=[1, 0, 2, 3, 4])\n",
    "        #masks_probs_flat = masks_probs_flat[0]\n",
    "        #masks_probs_flat = masks_probs.view(masks_probs.numel())\n",
    "        #true_masks_flat = true_masks.view(true_masks.numel())\n",
    "        \n",
    "        masks_probs_flat = masks_probs.flatten()\n",
    "        true_masks_flat = true_masks.flatten()\n",
    "        # Calculate the loss by comparing the predicted masks vector and true masks vector\n",
    "        # And sum the losses together\n",
    "        loss = dice_loss(masks_probs_flat,true_masks_flat)\n",
    "        epoch_loss += loss.item()\n",
    "        if count % 100 == 0:\n",
    "            print('{0:.4f} --- loss: {1:.6f}'.format(i * batch_size / N_train, loss.item()))\n",
    "        count = count + 1\n",
    "        # optimizer.zero_grad() clears x.grad for every parameter x in the optimizer.\n",
    "        # It’s important to call this before loss.backward(), otherwise you’ll accumulate the gradients from multiple passes.\n",
    "        optimizer.zero_grad()\n",
    "        # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "        # These are accumulated into x.grad for every parameter x\n",
    "        loss.backward()\n",
    "        # optimizer.step updates the value of x using the gradient x.grad.\n",
    "        optimizer.step()\n",
    "    print('Epoch finished ! Loss: {}'.format(epoch_loss / (i+1)))\n",
    "\n",
    "    # Perform validation with eval_net() on the validation data\n",
    "    val_dice = eval_net(net,val_loader)\n",
    "    print('Validation Dice Coeff: {}'.format(val_dice))\n",
    "    scheduler.step(val_dice)\n",
    "    print(\"lr\", lr)\n",
    "    # Save the model after each epoch\n",
    "    '''if os.path.isdir(model_save_path):\n",
    "        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    else:\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    print('Checkpoint {} saved !'.format(epoch + 1))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(net,full_img,out_threshold=0.5):\n",
    "    # set the mode of your network to evaluation\n",
    "    net.eval()\n",
    "\n",
    "    # convert from Height*Width*Channel TO Channel*Height*Width\n",
    "    #full_img = np.transpose(full_img,[2,0,1])\n",
    "\n",
    "    # convert numpy array to torch tensor, normalize to range (0,1)\n",
    "    #full_img = full_img/np.amax(full_img)\n",
    "    print(full_img.shape)\n",
    "    X_img = full_img.to(device)\n",
    "    print(X_img.shape)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        output_img = net(X_img.float())\n",
    "        #out_probs = output_img.squeeze(0).squeeze(0)\n",
    "        masks_probs = output_img.mean(0) # removes channel\n",
    "        masks_probs = masks_probs[0] # consider output[0]\n",
    "        # threshold the probability to generate mask: mask=1 if prob > out_threshold, set mask to uint8\n",
    "        out_mask_np = (masks_probs>out_threshold).cpu().numpy().astype('uint8')\n",
    "\n",
    "    return out_mask_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(blocks, unfold_shape):\n",
    "\n",
    "    blocks_orig = blocks.view(unfold_shape)\n",
    "    output_c = unfold_shape[1] * unfold_shape[4]\n",
    "    output_h = unfold_shape[2] * unfold_shape[5]\n",
    "    output_w = unfold_shape[3] * unfold_shape[6]\n",
    "    blocks_orig = blocks_orig.permute(0, 1, 4, 2, 5, 3, 6).contiguous()\n",
    "    blocks_orig = blocks_orig.view(1, output_c, output_h, output_w)\n",
    "    # Remove the dimension at 0th position and convert to numpy\n",
    "    blocks_orig = blocks_orig.squeeze(0).detach().numpy()\n",
    "    return blocks_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 48, 100, 100])\n",
      "torch.Size([1, 1, 48, 100, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Generate data blocks of block_size\\nimg_blocks, unfold_shape_img = get_data_blocks(data = img_padded, block_size = block_size)\\n#mask_blocks, unfold_shape_mask = get_data_blocks(data = mask_padded, block_size = block_size)\\n\\nimg_array = img_blocks.numpy()\\ntest_img = []\\n\\n\\nfor i in range(len(img_array[0])):\\n    test_img.append(img_array[0][i])\\n#test_img_mask = preprocess_image(test_img_paths)\\n\\norig_shape = len(test_img)\\nprint(len(test_img))\\n\\n#img_resize = cv2.resize(test_img_mask,(100,80))\\npredicted = []\\nfor image in test_img:\\n\\n    # Predict the mask\\n    mask_pred = predict_img(net=net,full_img=image, out_threshold=0.5)\\n    # Rescale the mask back to original image size\\n    #print(mask_pred.shape)\\n    predicted.append(mask_pred)\\n\\npred = torch.from_numpy(np.asarray(predicted)).type(torch.FloatTensor)\\nmask_recon = reconstruct(pred,unfold_shape_img)\\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load an image from testing dataset\n",
    "test_img_paths = \"data/Pre-processed training dataset/08029IVDI/FLAIR_preprocessed.nii.gz\"\n",
    "test_mask_paths = \"data/TrainingDataset_MSSEG/08029IVDI/Consensus.nii.gz\"\n",
    "vol = nib.load(test_img_paths)\n",
    "vol_affine = vol.affine\n",
    "m = nib.load(test_mask_paths)\n",
    "img = np.array(vol.get_data(), np.float32)\n",
    "img = nn.functional.interpolate(torch.from_numpy(img).unsqueeze(0).unsqueeze(0), size=imagesize, mode='trilinear')\n",
    "img = img/torch.max(img)\n",
    "#img_padded = zero_padding(img, block_size)\n",
    "mask_orig = np.array(m.get_data(), np.float32)\n",
    "mask_orig = mask_orig/np.amax(mask_orig)\n",
    "mask_orig = nn.functional.interpolate(torch.from_numpy(mask_orig).unsqueeze(0).unsqueeze(0), size=imagesize, mode='trilinear')\n",
    "mask_orig[mask_orig > 0.5] = 1\n",
    "mask_orig[mask_orig <= 0.5] = 0\n",
    "#mask_padded = zero_padding(mask, block_size)\n",
    "mask_recon = predict_img(net=net,full_img=img, out_threshold=0.1)\n",
    "'''\n",
    "# Generate data blocks of block_size\n",
    "img_blocks, unfold_shape_img = get_data_blocks(data = img_padded, block_size = block_size)\n",
    "#mask_blocks, unfold_shape_mask = get_data_blocks(data = mask_padded, block_size = block_size)\n",
    "\n",
    "img_array = img_blocks.numpy()\n",
    "test_img = []\n",
    "\n",
    "\n",
    "for i in range(len(img_array[0])):\n",
    "    test_img.append(img_array[0][i])\n",
    "#test_img_mask = preprocess_image(test_img_paths)\n",
    "\n",
    "orig_shape = len(test_img)\n",
    "print(len(test_img))\n",
    "\n",
    "#img_resize = cv2.resize(test_img_mask,(100,80))\n",
    "predicted = []\n",
    "for image in test_img:\n",
    "\n",
    "    # Predict the mask\n",
    "    mask_pred = predict_img(net=net,full_img=image, out_threshold=0.5)\n",
    "    # Rescale the mask back to original image size\n",
    "    #print(mask_pred.shape)\n",
    "    predicted.append(mask_pred)\n",
    "\n",
    "pred = torch.from_numpy(np.asarray(predicted)).type(torch.FloatTensor)\n",
    "mask_recon = reconstruct(pred,unfold_shape_img)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (48, 100, 100)\n",
      "(48, 100, 100)\n",
      "(48, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Segment\n",
    "mask_recon = torch.from_numpy(np.asarray(mask_recon)).type(torch.FloatTensor)\n",
    "#mask_interpolated = nn.functional.interpolate(mask_recon.unsqueeze(0).unsqueeze(0), size=img.shape, mode='trilinear')\n",
    "img_seg = mask_recon #* img\n",
    "img_seg = img_seg.squeeze().squeeze().numpy()\n",
    "img_seg_original = mask_orig.squeeze().squeeze().numpy()#*img\n",
    "img = img.squeeze().squeeze().numpy()\n",
    "#img = img.numpy()\n",
    "print(type(img_seg), img_seg.shape)\n",
    "print(img.shape)\n",
    "print(img_seg_original.shape)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def show_slices(slices):\n",
    "    \"\"\" Function to display row of image slices \"\"\"\n",
    "    fig, axes = plt.subplots(1, len(slices), figsize=(10,5))\n",
    "    for i, slice in enumerate(slices):\n",
    "        axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Center slices for MRI image')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "slice_0 = img[:, 60, :]\n",
    "slice_1 = img[:, 64, :]\n",
    "slice_2 = img[:, 70, :]\n",
    "show_slices([slice_0, slice_1, slice_2])\n",
    "plt.suptitle(\"Center slices for MRI image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Center slices for MRI image segmented by prediction')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "slice_0 = img_seg[:, 60, :]\n",
    "slice_1 = img_seg[:, 64, :]\n",
    "slice_2 = img_seg[:, 70, :]\n",
    "show_slices([slice_0, slice_1, slice_2])\n",
    "plt.suptitle(\"Center slices for MRI image segmented by prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Center slices for MRI image segmented original')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "slice_0 = img_seg_original[:, 60, :]\n",
    "slice_1 = img_seg_original[:, 64, :]\n",
    "slice_2 = img_seg_original[:, 70, :]\n",
    "show_slices([slice_0, slice_1, slice_2])\n",
    "plt.suptitle(\"Center slices for MRI image segmented original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 100, 100) 1551.0 1.0\n",
      "(48, 100, 100) 2030.0 1.0\n",
      "(48, 100, 100) 24228.988 1.0\n",
      "tensor(0.5219)\n",
      "[('data/Pre-processed training dataset\\\\07043SEME\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\07043SEME\\\\Consensus.nii.gz'), ('data/Pre-processed training dataset\\\\08002CHJE\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\08002CHJE\\\\Consensus.nii.gz'), ('data/Pre-processed training dataset\\\\08027SYBR\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\08027SYBR\\\\Consensus.nii.gz'), ('data/Pre-processed training dataset\\\\08029IVDI\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\08029IVDI\\\\Consensus.nii.gz'), ('data/Pre-processed training dataset\\\\08031SEVE\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\08031SEVE\\\\Consensus.nii.gz'), ('data/Pre-processed training dataset\\\\08037ROGU\\\\FLAIR_preprocessed.nii.gz', 'data/TrainingDataset_MSSEG\\\\08037ROGU\\\\Consensus.nii.gz')]\n"
     ]
    }
   ],
   "source": [
    "print(img_seg_original.shape, np.sum(img_seg_original), np.amax(img_seg_original))\n",
    "print(img_seg.shape, np.sum(img_seg), np.amax(img_seg))\n",
    "print(img.shape, np.sum(img), np.amax(img))\n",
    "print(1-dice_loss(torch.from_numpy(img_seg.flatten()), torch.from_numpy(img_seg_original.flatten())))\n",
    "print(val_img_mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
